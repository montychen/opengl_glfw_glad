* 入门
** 术语
- 绘制 Draw
- 渲染 Render
** OpenGL
- 在OpenGL 3.0版本之前，所有的OpenGL Context是统一的，都是一种兼容之前版本的模式（例如使用OpenGL 1.1编写的代码，在支持OpenGL 2.1的设备上可以正常的运行）。这些早期版本的OpenGL API也被称之为 *立即渲染模式 Immediate mode，也就是固定渲染管线* , 这也是相对后来的可编程管线来说shader来说的。在这个模式下绘制图形很方便，但是效率太低。
- 从OpenGL3.3开始不再建议使用立即渲染模式, *默认开启的是立即渲染模式* ，鼓励开发者 *手动开启核心模式 ( Core-profile ),  core profile不包含任何弃用功能* 。 在核心模式下，OpenGL迫使我们使用现代的函数。当试图使用一个已废弃的函数时，OpenGL会抛出一个错误并终止绘图。 现代函数要求使用者真正理解OpenGL和图形编程，它有一些难度，然而提供了更多的灵活性，更高的效率。后续OpenGL的更高的 版本都是在3.3的基础上， 引入了额外的功能，并没有改动核心架构。
#+begin_src c++
glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); //告诉GLFW我们要使用的OpenGL版本是3.3： 将主版本号(Major)和次版本号(Minor)都设为3
glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3);
glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); // 明确告诉GLFW我们使用的是核心模式(Core-profile
glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); // 如果使用的是Mac系统，需要这行代码；mac默认使用的是比较旧的版本，这行强制系统使用当前硬件支持的最新版本。

GLFWwindow* window = glfwCreateWindow(800, 600, "LearnOpenGL", NULL, NULL); //当我们用GLFW创建窗口的时候，GLFW会帮我们把默认帧缓冲创建和配置好
glfwMakeContextCurrent(window);     // 把当前线程的Context，设成窗口的Context

#+end_src
 
** 状态机
- OpenGL自身是一个巨大的 *状态机(State Machine)* ，整个绘制操作会按照图形管线的固定流程进行，如同一条流水线。OpenGL函数只是用来设置这条流水线的
  一些参数状态，并不是用来真正执行绘制操作的。 OpenGL的状态通常被称为 *上下文(Context)* 。假设我们想画线段而不是三角形的时候，可以通过OpenGL的函数
  调用来改变上下文状态，从而告诉OpenGL如何去绘图。一旦我们改变了OpenGL的状态为绘制线段，下一个绘制命令就会画出线段而不是三角形。
  
- 在OpenGL中一个 *Object对象* 是指一些选项的集合，它代表OpenGL状态的一个子集。比如，我们可以用一个对象来代表绘图窗口的设置，之后我们就可以设置它的大小、支持的颜色位数等等。可以把对象看做一个C风格的结构体Struct。
  #+begin_src c++
// 创建 *对象* , 然后用一个id保存它的引用
unsigned int objectId = 0;
glGenObject(1, &objectId);

// 将对象绑定至上下文的目标位置（例子中窗口对象目标的位置被定义成GL_WINDOW_TARGET）
glBindObject(GL_WINDOW_TARGET, objectId);

// 设置当前绑定到 GL_WINDOW_TARGET 的对象的一些选项
glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_WIDTH, 6500);
glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_HEIGHT, 600);

// 将目标位置的对象id设回0，解绑这个对象。将上下文对象设回默认.
// 设置的选项将被保存在objectId所引用的对象中，一旦我们重新绑定这个对象到GL_WINDOW_TARGET位置，这些选项就会重新生效。
glBindObject(GL_WINDOW_TARGET, 0);
  #+end_src
  - 使用对象的一个好处是在程序中，我们不止可以定义一个对象，并设置它们的选项，每个对象都可以是不同的设置。在我们执行一个使用OpenGL状态的操作的时候，只需要绑定含有需要的设置的对象即可。比如说我们有一些作为3D模型数据（一栋房子或一个人物）的容器对象，在我们想绘制其中任何一个模型的时候，只需绑定一个包含对应模型数据的对象就可以了（当然，我们需要先创建并设置对象的选项）。

* 基础知识
** 坐标
*** OpenGL世界坐标系
*OpenGL世界坐标系，使用右手坐标系* ： 伸开右手，大拇指指向X轴正方向，食指指向Y轴正方向，其他三个手指指向Z轴正方向。

原点（0.0，0.0，0.0）在屏幕的中间，X轴正向朝右， Y轴正向朝上，Z轴垂直于屏幕正向朝外（从屏幕指向你的后面）；看向屏幕， 我们的视线方向是Z轴的负方向。

#+ATTR_latex: :width 700   #+ATTR_HTML: :width 700  #+ATTR_ORG: :width 700
[[file:webgl/webgl_coord.png]]


- 我们在传入顶点坐标时，使用的就是世界坐标系。它需要经过转换，最终变为屏幕坐标系。

- *OS的屏幕坐标 + OS的窗口坐标：屏幕的左上角为原点* ，X轴正向向右，Y轴正向向下。不管是 iOS 还是 Windows 等等 GUI 编程，都是这样。
- *OpenGL的窗口坐标：原点在窗体的左下角* 。 X轴正向向右，Y轴正向朝上。
- 屏幕 > 窗体 > 视口的关系：屏幕包含窗体，窗体显示在屏幕上； 窗体包含视口。

*** 视口ViewPort
*视口* ：即告诉OpenGL应把 *渲染Render* 之后的图形绘制在窗体的哪个部位。当视口区域是整个窗体时，OpenGL将把渲染结果绘制到整个窗口。函数glViewPort可以用来改变视口区域的位置和大小:
#+begin_quote
void glViewport(GLint x, GLint y, GLint width, GLint height)
- 参数X，Y指定了视口的左下角在窗口中的位置（使用的是OpenGL窗口坐标的值，原点在左下角），一般情况下为（0，0），也就是在窗口的左下角。
- Width和Height指定了视口的宽度和高度。

例如： glViewport(100, 100, 800, 600); 没把视口的左下角放在窗口的左下角，效果如图所示
[[file:OpenGL/viewport.png]]

#+end_quote

*** 纹理坐标texture coordinates：纹理通常来说就是一张图片
- 纹理坐标：原点（0.0， 0.0）在左下角，  x轴正向朝右， y轴正向朝上。坐标值和图像大小无关，不管是128*128还是128*256的图像，其右上角坐标始终是（1.0，1.0）
- 纹理坐标就是纹理图像上的坐标，纹理坐标是二维的，为了和广泛使用的xy坐标区分开来， 习惯用s和t来命名纹理坐标（st坐标系统）。
- 不论图片尺寸有多大，长和宽各是多少，强制规定了纹理坐标总是从0到1之间取值。
- 通过纹理坐标可以在纹理图像上获取纹素的颜色。

#+ATTR_latex: :width 400   #+ATTR_HTML: :width 400  #+ATTR_ORG: :width 400
[[file:webgl/texture_coord.png]]

*** NDC 标准化设备坐标(Normalized Device Coordinates)
标准化设备坐标NDC是一个x、y和z值在-1.0到1.0的一小段空间。任何落在范围外的坐标都会被丢弃/裁剪，不会显示在你的屏幕上。 和OpenGL的世界坐标系使用的右手坐标系一样： 原点（0.0，0.0，0.0）在屏幕的中间，X轴正向朝右， Y轴正向朝上，Z轴垂直于屏幕正向朝外（从屏幕指向你的后面）；看向屏幕， 我们的视线方向是Z轴的负方向。如下图所示(忽略z轴)：
#+ATTR_latex: :width 650   #+ATTR_HTML: :width 650  #+ATTR_ORG: :width 650
[[file:OpenGL/ndc.png]]
*** 齐次坐标（Homogeneous coordinates）: 能用 左乘矩阵 来统一完成所有的坐标变换

*齐次坐标*  就是将一个原本是n维的向量用n+1维来表示。 比如，三维中的点（x, y, z）表示成 （x, y, z, w）。

齐次坐标的作用：能够统一使用 *左乘矩阵* 来完成所有的坐标变换：平移、缩放、旋转、错切(表示弹性物体的变形）、对称、投影。没有w分量矩阵运算实现不了平移.
*左乘矩阵* : 指的是矩阵和顶点相乘时，矩阵放在左边，如: 矩阵 x 顶点 = 变换后的顶点.

那么，统一使用矩阵来完成坐标变换的有哪些好处？
- GPU的设计天然就更适合矩阵运算。
- 更重要的是，矩阵可以通过相乘，来进行可以组合，也就是把多个连续的变换矩阵组合成一个矩阵，这样可以大大提高效率。


想要从齐次向量得到3D向量，我们可以把x、y和z坐标分别除以w坐标。我们通常不会注意这个问题，因为w分量通常是1.0。
- 若w==1，则向量(x, y, z, 1）表示的是空间中的点。
- 若w==0，则向量(x, y, z, 0) 表示的是方向。 此时，这个向量就不能位移，”平移一个方向”是毫无意义的。

** GLSL着色语言(OpenGL Shading Language)基础
*** GLSL和OpenGL的通信： uniform、inout
*Uniform* 是一种从CPU应用向GPU着色器发送数据的一种方式。Uniform是全局的，在某一着色器里声明了它，其他着色器就可以使用它。
#+ATTR_latex: :width 650   #+ATTR_HTML: :width 650  #+ATTR_ORG: :width 650
[[file:OpenGL/glsl_opengl.jpg]]

*** 顶点着色器(Vertex Shader)
#+begin_src glsl
#version 330 core                   // 声明使用的版本，同样明确表示使用核心模式。
// 顶点属性变量(Vertex Attribute)不能声明为数组或结构体。in 只能用于数据类型 float, vec2, vec3, vec4, int, ivec2, ivec3, ivec4, uint, uvec2, uvec3, uvec4, mat2, mat2x2, mat2x3, mat2x4, mat3, mat3x3, mat3x4, mat4, mat4x2, and mat4x3.
layout (location = 0) in vec3 aPos; //顶点属性变量用in关键字声明; layout (location = 0)设定了变量的位置值，每个顶点属性的位置值要唯一；顶点变量是只读的，不能修改。

void main()
{
    gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0);
}
#+end_src

*** 片段着色器(Fragment Shader): 片段着色器所做的是计算像素最后的颜色输出。
#+begin_src glsl
#version 330 core                // 声明使用的版本，同样明确表示使用核心模式。
out vec4 FragColor;              // 片段着色器只需要一个输出变量，用out关键字声明输出变量，这里把变量命名为FragColor。

void main()
{
    FragColor = vec4(1.0f, 0.5f, 0.2f, 1.0f); // 颜色用RGBA表示：红色、绿色、蓝色和alpha(透明度，1.0代表完全不透明)。每个分量的值在0.0到1.0之间
}
#+end_src

*** 编译着色器
#+begin_src glsl
// 1. 编译顶点着色器
unsigned int vertexShader;                       // 声明一个unsigned int来存储下面创建的着色器ID
vertexShader = glCreateShader(GL_VERTEX_SHADER); // 着色器类型GL_VERTEX_SHADER，表示我们创建的是一个顶点着色器
glShaderSource(vertexShader, 1, &vertexShaderSource, NULL); // 把这个着色器源码附加到着色器对象上
glCompileShader(vertexShader);                              // 编译它

// 2.编译片元着色器
unsigned int fragmentShader;
fragmentShader = glCreateShader(GL_FRAGMENT_SHADER); // 创建片元着色器
glShaderSource(fragmentShader, 1, &fragmentShaderSource, NULL);
glCompileShader(fragmentShader);

// 3. 链接着色器程序: 是多个着色器合并之后并最终链接完成的版本
unsigned int shaderProgram;
shaderProgram = glCreateProgram();

glAttachShader(shaderProgram, vertexShader);
glAttachShader(shaderProgram, fragmentShader);
glLinkProgram(shaderProgram);   // 把各个着色器链接(Link)为一个着色器程序对象

// 4. 激活这个程序对象, 已激活着色器程序的着色器将在我们发送渲染调用的时候被使用。
glUseProgram(shaderProgram);

// 5. 在把着色器对象链接到程序对象以后，记得删除着色器对象，我们不再需要它们了
glDeleteShader(vertexShader);
glDeleteShader(fragmentShader);

#+end_src

#+begin_quote
void glShaderSource(	GLuint shader, GLsizei count,  const GLchar **string, const GLint *length)
- 第一个参数是要编译的着色器对象
- 第二参数指定了传递的源码字符串数量，这里只有一个。
- 第三个参数是顶点着色器真正的源码
- 第四个参数我们先设置为NULL。

#+end_quote

*** VBO & VAO & EBO
#+begin_quote
VBO、VAO和 EBO 都是显卡硬件中的一块内存区域，它们的作用是在显存中提前开辟好一块内存，用于缓存顶点数据或者图元索引数据，我们可以一次性的发送一大批在CPU定义的数据到GPU的VBO中，而不是每个顶点发送一次，渲染时， 直接从显存的VBO中取出顶点数据，不需要从CPU传输数据，效率高。
#+end_quote

*VBO(顶点缓冲对象：Vertex Buffer Object)* 用于存储顶点数据，如顶点坐标，顶点法向量，顶点颜色数据等。
- 可以开辟很多个VBO，每个VBO有唯一标识ID，这个ID对应着具体的VBO的显存地址，通过这个ID可以对特定的VBO内的数据进行存取操作。

*VAO(顶点数组对象Vertex Array Object)*
- 保存了所有顶点属性数据的状态结合，VAO本身并没有存储顶点的相关属性数据，这些信息还是存储在VBO中，VAO相当于是对多个VBO的引用， 把相关的VBO组合在一起作为一个对象统一管理。
- VAO中有一个属性列表，默认有16个属性(0 - 15)，我们可以为属性指定数据，其中属性可以是顶点位置，颜色，法线，纹理坐标等等我们需要 的数据，其中的每一个属性对应的数据其实就是VBO
- 如果我们已经为vao绑定过数据了，下一次使用的时候就不需要重新绑定了，直接使用这个vao就可以了，相当于我们已经有模型的数据了。
- 在bind和unbind（glBindVertexArray(0)）之间的操作都是针对这一个vao对象的，也就是执行VAO绑定之后，其后的所有VBO和EBO配置都是这个VAO对象的一部分

#+begin_src c++
float vertices[] = {            // 在CPU中：声明三角形的顶点数据
-0.5f, -0.5f, 0.0f, // left
0.5f, -0.5f, 0.0f, // right
0.0f,  0.5f, 0.0f  // top
};

// 1.开辟（声明/获得）显存空间并分配ID
unsigned int VBO, VAO;
glGenVertexArrays(1, &VAO);     // 创建VAO
glGenBuffers(1, &VBO);          // 创建1个缓存对象，并把缓存的ID保存在VBO中，每个VBO缓冲都有一个唯的ID。

// 绑定VAO, 执行VAO绑定之后其后的所有VBO配置都是这个VAO对象的一部分
glBindVertexArray(VAO);

// VBO绑定、传输数据CPU => GPU、把一个VBO和一个顶点属性关联起来
glBindBuffer(GL_ARRAY_BUFFER, VBO); // 绑定缓冲类型：顶点缓冲对象的缓冲类型是GL_ARRAY_BUFFER。
glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);  //一次性把CPU中定义的顶点数据传到GPU的VBO。 CPU => GPU
glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0); // 一个VBO对应一个顶点属性，这里把两者管理起来。
glEnableVertexAttribArray(0);   // glEnableVertexAttribArray以顶点属性位置值为参数，启用顶点属性；顶点属性默认是禁用的。

// 解绑
glBindBuffer(GL_ARRAY_BUFFER, 0); // VBO解绑
glBindVertexArray(0);             // VAO解绑
#+end_src

*EBO* (索引缓冲对象：Element Buffer Object)存储的是顶点位置的索引，目的是为了解决同一顶点重复调用的问题，减少内存浪费。当需要使用重复顶点的时候，可以通过顶点索引来调用顶点，而不是重复记录。
- 当用EBO绑定顶点索引的方式绘制模型时，需要 *使用glDrawElements而不是glDrawArrays*


*** 绘制
OpenGL中所有的图形都是通过分解成三角形的方式进行绘制，glDrawArrays函数负责把模型绘制出来，它使用当前激活的着色器程序，当前VAO对象中的VBO顶点数据和属性配置来绘制出来基本图形。

#+begin_src c++
glUseProgram(shaderProgram);    // 激活着色器程序
glBindVertexArray(VAO);
glDrawArrays(GL_TRIANGLES, 0, 3); // 触发绘制开始执行 >> 先把缓冲区的数据传给顶点属性 >> 然后着色器开始执行
#+end_src


** 向量： 向量相乘可以交换位置；点乘和叉乘

** 矩阵： 矩阵相乘不能交换位置
*** OpenGL API接受的矩阵要求是 *列主序*
在实际编程语言中，我们使用的一维数组来存储4x4矩阵的16个元素。所谓的行存储和列存储的区分就在于数组的前四个元素存储的是矩阵的第一列还是第一行；表示列的称为列存储，表示行的成为行存储。
#+ATTR_latex: :width 800   #+ATTR_HTML: :width 800  #+ATTR_ORG: :width 800
[[file:webgl/column_order.png]]

*** 单位矩阵(Identity Matrix): 主对角线元素为1，其余元素为0, 可简记为I。
在c++，用glm构造一个单位矩阵 glm::mat4(1.0);
#+begin_src c++
glm::mat4 myIdentityMatrix = glm::mat4(1.0);
#+end_src
#+ATTR_latex: :width 400   #+ATTR_HTML: :width 400  #+ATTR_ORG: :width 400
[[file:webgl/identity_matrix.png]]


** 视点 or 相机位置
在一个场景中，我们希望改变观察者的位置和观察角度。用于改变观察者方位和角度的变换，就是视图变换。默认情况下， *视点或者说相机位于原点(0,0,0)， 且视线朝着-Z方向。 也就是说，只有在z<0的地方绘图，才有可能被观察到* 。

创建视图矩阵: Matrix4.setLookAt(eyeX, eyeY, eyeZ, atX, atY, atZ, upX, upY, upZ)
- eyeX,eyeY, eyeZ: 指定视点
- atX, atY, atZ: 观察目标点
- upX, upY, upZ: 指定上方向

为了确定相机视角，需要3项信息：
1. 视点：观察者的位置，视线的起点。习惯用（eyeX, eyeY, eyeZ)表示
2. 观察目标点：被观察物体所在的点，习惯用（atX, atY, atZ）表示。可以用来确定视线(at - eye)，视线从视点出发，穿过观察目标并继续延伸
3. 上方向：如果仅仅确定了视点和目标点，观察者还是可能以视线为轴旋转的，如下图所示。所以，为了将观察者固定住，还需要指定上方向。习惯用（upX, upY, upZ)表示。
#+ATTR_latex: :width 800   #+ATTR_HTML: :width 800  #+ATTR_ORG: :width 800
[[file:webgl/camera.png]]

** R旋转 Rotate & 为什么逆时针是旋转正方向
在OpenGL的右手坐标系下，旋转规则是： 确定旋转轴后，右手握成拳头，拇指指向旋转轴的正方向，其余手指的弯曲方向即为旋转的正方向，跟手指弯曲方向一致的
旋转记为正向，相反则为负向。例如： Z轴正旋转或者Z轴逆时针旋转，就是大拇指指向Z轴，其余手指弯曲的方向就是Z轴旋转正方向。这个正方向，其实是逆时针
方向，所以一般规定逆时针为正就是这么来的，也就是说，旋转方向可以用旋转角度值的正负来表示。

为了描述旋转（比如：绕Z轴，逆时针旋转了β角度），必须指明3个要素：
- 旋转轴（图像将围绕旋转轴旋转）
- 转转角度（图形旋转经过的角度）
- 旋转方向（顺时针or逆时针）： 在调用旋转函数时，一般不会传入一个表示旋转方向的参数。因为如果旋转的角度是正值，那就是逆时针旋转，原因如上所述。

#+ATTR_latex: :width 300   #+ATTR_HTML: :width 300  #+ATTR_ORG: :width 300
[[file:webgl/z_rotation.png]]


** 帧缓冲Frame buffer & 深度缓冲Depth Buffer(Z-Buffer)消隐算法 & 颜色缓冲Color Buffer
*FrameBuffer帧缓冲* 里存储的内容和视口（屏幕）上的每个像素一一对应的，对帧缓冲内容的修改其实就是对视口（屏幕）上显示内容的修改。另外， 对片元Fragment的处理， 就是在利用和修改帧缓冲的数据。Frame buffer是显卡硬件的一部分，包含了完整的帧数据.
- OpenGL 实际上并不是把图像直接绘制到计算机屏幕上，而是渲染到一个帧缓冲区，然后需要由这台机器来负责把帧缓冲区的内容绘制到屏幕上的一个窗口中。有不少库都可以支持这一部分工作，GLFW 是最流行的。GLFW 库包含了 GLFWwindow 类，我们可以在其上进行 3D 场景绘制。
#+begin_src c++
GLFWwindow* window = glfwCreateWindow(800, 600, "LearnOpenGL", NULL, NULL); // 当我们用GLFW创建窗口的时候，GLFW会帮我们把默认帧缓冲创建和配置好
#+end_src
- 当我们使用GLFW创建窗口的时候，GLFW会帮我们把默认帧缓冲创建和配置好。通常，我们只需要把默认帧缓冲区作为绘图表面，但是又有些特殊情况，比如阴影贴图、动态反射等需要渲染到纹理操作的，如果使用窗口系统提供的默认帧缓冲区，效率会比较低低下，因此需要自定义自己的帧缓冲区。OpenGL允许我们手动创建帧缓冲区，来将数据绘制到我们自己的帧缓冲中，也就是常说的 *离屏渲染* 。
- *Frame buffer包含color buffer，stencil buffer，depth buffer等若干buffer。 只有color buffer用于最后的像素显示，其他的都是用来辅助fragment的处理* 。 而且Frame buffer 中只有颜色缓冲区ColorBuffer是必须要有的，其它的都是可选的，如：深度缓冲区DepthBuffer，模板缓冲区StencilBuffer


*Stencil Buffer模版缓冲*: 作用就是限制绘制的图元区域, 过滤丢弃一些片段，只留下想要的东东。 做法是按照窗口宽高创建一个矩阵，矩阵由0,1组成，其中由1组成的区域代表相匹配的图元需要提交到后续流程进行测试和绘制，而由0组成的区域的片元则直接被丢弃，起到一个筛选作用，而这个0,1数值矩阵所在的显存区域则称为模版缓冲区。 例如：我们将模板缓存中的一个矩形区域设置为1，我们的立方体在绘制时，我们将只绘制模板值为1的像素区域，从而达到控制像素绘制与否的目的。
#+ATTR_latex: :width 650   #+ATTR_HTML: :width 650  #+ATTR_ORG: :width 650
[[file:OpenGL/stencil.png]]

- 模板缓冲区可以为屏幕上的每个像素点保存一个无符号8bit整数。
- 在渲染Render的过程中，可以用这个值与一个预先设定的参考值相比较，根据比较的结果来决定是否更新相应的像素点的颜色值。这个比较的过程被称为模板测试。
- 模板测试发生在透明度测试（alpha test）之后，深度测试（depth test）之前。如果模板测试通过，则相应的像素点更新，否则不更新。

*Z-Buffer(也叫DepthBffer深度缓冲)* : 存储每个可见像素的深度值, 这是z坐标经过投影变换后的一个介于0.0和1.0之间的深度值。
- 在像素级上以近物来取代远物，和绘制的先后顺序无关，前面的像素挡住后面的，后面的不可见。 也叫消隐Visible surface detection。
- *深度测试Depth Testing*: 当片元Fragment想要输出它的颜色时，OpenGL会将它的深度值和z缓冲进行比较，如果当前片元在其它片元之后，它会被丢弃，否则将会覆盖。
- 近处的物体有很大的深度精度； 远处的物体，由于深度精度不够很容易导致像素的前后关系判断失误，不能正确消隐，导致远处的物体产生闪烁现象



** 纹理Mipmap
*纹理mipmap* 的基本思路是，对远处的东东，用尺寸较小、分辨率较低的纹理；对近处的东东，用尺寸交大、分辨率较高的纹理。 因为在三维世界中, 显示一张图的大小与摄象机机距离模型的远近位置有关,近的地方,图片就大一些,远的地方图片就会小一些。 当摄像机较 远的时候，用精细的贴图玩家也看不见， 而且还浪费资源，此时完全可以用更小的贴图。
- mipmap的关键是预先将贴图压缩成很多逐渐缩小的图片, 按照2的倍数 *每次缩小一半直到1X1* ， 把缩小的图都 *预先存储* 起来。例如 一张64*64的图片,会产生64*64, 32*32,16*16,8*8,4*4, 2*2,1*1的7张图片,当屏幕上 需要绘制像素点 为20*20 时，程序只是利用 32*32 和 16*16 这两张图片来计算 出即将显示为 20*20 大小的一个图片，这比单独利用 32*32 的那张原始片计算出来的图片效果要好得多，速度也更快.
- mip level： 一系列缩略图的编号即为mip level。 *level 0为原图*，之后的每一个level 都比上一个level长宽缩减到一半， 也就是按照2的倍数进行缩小 直到1X1。 Mip层0是最初的图像，之后的mip层被称为mip链。

* 图形管线 PipeLine

** 图形管线的3个阶段: 应用、几何、光栅
#+ATTR_latex: :width 650   #+ATTR_HTML: :width 650  #+ATTR_ORG: :width 650
[[file:OpenGL/pipeline_3stage.jpg]]


** 图形管线分工
#+ATTR_latex: :width 650   #+ATTR_HTML: :width 650  #+ATTR_ORG: :width 650
[[file:OpenGL/pipeline1.png]]


** 变换 Transformation: 几何变换 -> 投影裁剪NDC -> 视口变换
*顶点*  : 管线的输入是那些预先定义好的三维空间中的点，而不是直接输入三角形，在后面三维空点的投影到二维屏幕后，再决定那三个点形成一个三角形。

*MVP* 几何单元（比如三角形）在经过: M模型矩阵变换、V视角矩阵变换、P投影矩阵变化以及透视除法后，坐标变换到归一化的NDC坐标系下[-1， 1] 。在知道输出 屏幕大小的情况下，通过视口变换可将x/y变换到窗口坐标下（x∈【0，width】 y∈【0，height】z不变）。至此我们即将所有三角形投射到raster_space中。

#+ATTR_latex: :width 700   #+ATTR_HTML: :width 700  #+ATTR_ORG: :width 700
[[file:OpenGL/MVP.jpg]]

*** 投影: 裁剪clipping(frustum culling视椎体剔除) + 透视除法生成NDC[-1, 1]
*投影矩阵(projection matrix)* :显示器是二维的, 一个3D场景需要被投影到屏幕上成为一个2D图像，这称为投影变换，需要用到投影矩阵，投影干两件事:
1. 投影矩阵会创建一个视椎体对物体坐标进行 *裁剪clipping(即frustum culling视椎体剔除)* 。实现方式就是投影矩阵先把顶点坐标从eye coordinates观察空间变换到裁剪坐标clip coordinate, 然后再把视椎体外不可见的部分裁剪掉 。
2. *裁剪坐标再通过透视除法被变换到标准化设备坐标NDC[-1, 1]* ，这一步是用裁剪坐标的w分量除裁剪坐标(x/w, y/w, z/w, w/w)实现的。

**** 视锥体frustum、裁剪坐标clipping coordinates
- 视锥体（frustum），它包含六个平面（近平面、远平面、上平面、下平面、右平面和左平面）
- 裁剪坐标（clipping coordinates）：位于这个视锥体以外的顶点都会被剪裁掉，所得的坐标结果成为裁剪坐标（clipping coordinates）
- 视锥体的形状决定了3D到2D的投影类型，如果近平面和远平面尺寸一致，那么物体上的顶点不论远近都以统一的方式投影在屏幕上，这是正交投影orthographic projection。否则就是透视投影perspective projection。简单来说， *透视投影有近大远小的效果* ，而正交投影没有。
#+ATTR_latex: :width 500   #+ATTR_HTML: :width 500  #+ATTR_ORG: :width 500
[[file:webgl/frustum.png]]

**** 近平面的宽高比和视口宽高比 & 图像变形
不管是正交投影orthographic还是透视投影，最终都是将视景体内的物体投影在近平面上，这也是 3D 坐标转换到 2D 坐标的关键一步。 在用opengl绘制一张图片 的时候经常会遇到图片被拉伸或挤压变形的问题，为了解决该问题，关键就是让 *近平面的宽高比和视口宽高比保持一致* ，并且以较短的一边作为 1 的标准，让图像保持居中。

#+ATTR_latex: :width 650   #+ATTR_HTML: :width 650  #+ATTR_ORG: :width 650
[[file:OpenGL/viewport_wh.png]]


** 光栅化 Rasterization： 找出最佳逼近三角形的像素集 + 插值算出三角形内部所有像素点的颜色
一定要牢记，显示屏是二维的，GPU 所需要做的是将三维的数据，绘制到二维屏幕上。*光栅化* 就是将一个几何图元转变为屏幕栅格上的二维图像的过程，这个二维图像由光栅上离散的点阵构成（屏幕上的点就是像素），每个点都包含了 *颜色、深度和纹理* 数据。将该点和相关信息叫做一个 *片元（fragment）* 。 粗略地讲：根据图形的定义的那些顶点在经过各种矩阵变换后也仅仅是顶点。而由顶点构成的三角形要在屏幕上显示出来，除了需要三个顶点的信息以外，还需要 *插值算出三角形内部的所有像素的颜色* 。光栅化就是干这个的。主要有2步：
1. 在栅格点阵上找出最佳逼近于图形形状(比如三角形）的像素集。逼近的过程本质可以认为是： *连续量向离散量的转换* 。
2. 给像素指定合适的颜色值，包括 *插值算出三角形内部所有像素点的颜色* （Z值、法向、纹理坐标等）。可以通过光照、纹理的计算，来确定像素的颜色值。
   #+ATTR_latex: :width 650   #+ATTR_HTML: :width 650  #+ATTR_ORG: :width 650
[[file:OpenGL/rasterization.png]]




* Phong光照模型 = ambient + diffuse + specular
*结合Phong光照模型，最终作用于物体的光照效果就是 = （ambient + diffuse + specular）  ✖  物体的基本色*

** 环境光(Ambient light)：模拟间接光照。
环境光给予物体各个点的光照强度相同，且没有方向之分，所以在只有环境光的情况下，同一物体各点的明暗程度均一样，因此，只有环境光是不能产生具有真实感的图形效果。环境光指的是那些被多次反射后，从各个角度间接照射物体的光，理想的环境光有如下特性：强度一致，没有空间或方向性； 习惯用一个颜色常量来模拟：

*环境光 = 入射光颜色向量I ️✖ 物体表面光的反射系数K*

#+ATTR_latex: :width 650   #+ATTR_HTML: :width 650  #+ATTR_ORG: :width 650
[[file:OpenGL/ambient.png]]

*** 例：把环境光照添加到场景里： 用光的颜色乘以一个很小的常量环境因子，再乘以物体的颜色，然后将最终结果作为片段的颜色：
#+begin_src c++
float ambientStrength = 0.1;                 //  物体表面的光的反射系数
vec3 ambient = ambientStrength * lightColor; // 这个就是环境光, lightColor是入射光颜色向量

vec3 result = ambient * objectColor;         // 计算出：环境光作用于物体的效果， objectColor 是物体的基本色
FragColor = vec4(result, 1.0);
#+end_src


** 漫反射(Diffuse reflection): 光源直接照射物体产生的效果。（大但不光亮）
漫反射：指的是粗糙表面等强度均匀的向四周反射光。 漫反射和光的入射角度有关，和反射的角度无关，反射光是均匀的反射到各个方向，也就是和视点无关，
入射光垂直照射物体表面，反射光最强；也就是说物体越正对着光源的部分，就会越亮。

*漫反射 =  入射光颜色向量I ✖ 物体表面光的反射系数K  ✖ (L.N)*

*OpenGL的实现：diffuse = K * lightColor * max( dot(N, L),  0)*

点乘 N.L 光的入射角如果大于等于90度，值就等于或者小于0，就没反射光了，应该是黑的，这里做了处理。

- I 入射光颜色向量, 习惯用lightColor表示。
- K 物体表面光的反射系数
- L 是从P点指点向光源的单位向量（注意，是由P点指向光源，不要弄反了) = normalize（点光源向量 - P点向量）
- N 入射点P的单位法向量 = normalize(N)

#+ATTR_latex: :width 650   #+ATTR_HTML: :width 650  #+ATTR_ORG: :width 650
[[file:OpenGL/diffuse.png]]


** 高光 or 镜面反射(Specular reflection)：光源直接照射物体产生的效果。（小而亮）
光滑的表面，在点光源的照射下， 会产生一块特别亮的区域（高光点）。原因是：在理想镜面情况下，入射角等于反射角，观察者只能在 反射方向一侧才能看到反射光；但现实是没有完全光滑的表面， 所以实际的反射区域是一个小的角度范围，这个范围就是高光区域。

*镜面反射 =  入射光颜色向量I ✖ 物体表面光的反射系数K  ✖ (V.R)^n*

*OpenGL的镜面反射： specular = K * lightColor * pow( max( dot(V, R),  0),  n)*

反射光向量R的计算还是比较麻烦的，改进后的就是Blinn-phong 反射模型，它省去了计算反射光向量R的两个乘法运算，速度更快。
*Blinn-Phong镜面反射 = 入射光颜色向量I ✖ 物体表面光的反射系数K  ✖ (N.H)^n*

*OpenGL的Blinn-Phong镜面反射： specular = K * lightColor * pow( max( dot(N, H),  0),  n)*

- I 入射光颜色向量, 习惯用lightColor表示。
- K 物体表面光的反射系数
- L 是从P点指点向光源的单位向量（注意，是由P点指向光源，不要弄反了) = normalize（点光源向量 - P点向量）
- N 入射点P的单位法向量 = normalize(N)
- n 是物体表面的光滑指数，值越大表示越光滑，反射光越集中，高光区域就越小。n = 10, 20, 30, 80, 160
- V 表示从P点指向视点的向量，
- R 代表反射光向量 =  2(N • L)N − L = 2 * max( dot(N, L), 0) * N - L
- H 二分向量，它是沿L和V的角平线的单位向量 = normalize(L + V)

#+ATTR_latex: :width 650   #+ATTR_HTML: :width 650  #+ATTR_ORG: :width 650
[[file:OpenGL/specular.jpg]]
*** 例： 环境光 + 漫反射 + 高光同时作用于物体的效果
#+begin_src c++
// ambient
float ambientStrength = 0.1;                 //  Ka物体表面的光的反射系数
vec3 ambient = ambientStrength * lightColor; // 这个就是环境光的结果，lightColor是入射光颜色向量

// diffuse
vec3 norm = normalize(Normal);  // N 法向量：垂直于P点的向量归一化
vec3 lightDir = normalize(lightPos - FragPos); // L 是从P点指点向光源的单位向量 = 点光源向量 - P点向量
float diff = max(dot(norm, lightDir), 0.0);    // 点乘 N.L 光照的入射角如果大于等于90度，就没反射光了，应该是黑的，所以这里做了处理。
vec3 diffuse = diff * lightColor;              // 漫反射的结果

// specular
float specularStrength = 0.5;   // Ks 物体表面光的反射系数
vec3 viewDir = normalize(viewPos - FragPos); // V 表示从P点指向视点的向量，
vec3 reflectDir = reflect(-lightDir, norm);  // 通过GLSL内置函数reflect算出反射光向量R. 光线的入射方向和L的方向是相反的，所以这里对lightDir取反
float spec = pow( max( dot(viewDir, reflectDir),  0.0), 32);
vec3 specular = specularStrength * spec * lightColor;

vec3 result = (ambient + diffuse + specular) * objectColor; // 计算出：环境光 + 漫反射 + 高光同时作用于物体的效果
FragColor = vec4(result, 1.0);
#+end_src


* OpenGL函数

** glBufferData( GLenum target,  GLsizeiptr size,  const GLvoid * data,  GLenum usage ) 把在CPU中定义的数据传输到GPU的缓冲中。 CPU => GPU
1. 目标缓冲的类型：顶点缓冲对象当前绑定到GL_ARRAY_BUFFER目标上。
2. 指定传输数据的大小(以字节为单位)；用一个简单的sizeof计算出顶点数据大小就行。
3. 是我们希望发送的实际数据。
4. 指定了我们希望显卡如何管理给定的数据。它有三种形式：
   - GL_STATIC_DRAW ：数据不会或几乎不会改变。
   - GL_DYNAMIC_DRAW：数据会被改变很多。
   - GL_STREAM_DRAW ：数据每次绘制时都会改变。

** glVertexAttribPointer(index, size, type, normalized, stride, GLvoid * pointer) 一个VBO对应一个顶点属性。该函数建立他们的对应关系
设置顶点属性指针，把VBO中的数据，赋值给某个在顶点着色器中定义的顶点属性(Vertex Attribute)。通过顶点属性变量layout(location = 0)定义的位置索引值，来建立关联。每个顶点属性从一个VBO获得它的数据，具体是哪个VBO（程序可以有多个VBO）？是通过在调用glVertexAttribPointer时绑定到GL_ARRAY_BUFFER的VBO决定。
1. index：指定要配置的顶点属性。用位置索引值来指定，也就是在顶点着色器中，定义顶点属性变量时，由layout(location = 0)定义的值。
2. size：顶点属性的分量个数（1到4）。例如顶点属性如果是vec3类型，那就是有3个分量，所以值就是3。
3. type：指定顶点属性分量的数据类型。
4. normalized：如果设置为GL_TRUE，表示要做归一化处理，所有数据都会被映射到0（对于有符号型signed数据是-1）到1之间。
5. stride: 指定相邻两个顶点数据间间隔的字节数，这里是0。0表示相邻两个顶点是紧密排列的（在两个顶点属性之间没有空隙），OpenGL将自动推算出stride的值。
   - stride是相对于一组属性来说的，而不是对于属性的每一个成分来说的。以具有3个分量的顶点属性为例，有x、y、z三个成分，将x、y、z看做一组，stride是每一组之间的步幅。
6. offset：指定顶点数据在缓冲区起始位置的偏移量，这里是0

** void glDrawArrays(mode, first, count) 绘制图元
触发绘制开始执行 >> 先把缓冲区的数据传给顶点属性 >> 然后着色器开始执行：先逐顶点执行vertex shader...再逐片元执行fragment shader。
1. mode绘图模式：需要绘制的图元primitives类型： 可以绘制的3种基本图元是：点、线、三角形。其它的图形都是由这3种基本图元组成。
   - GL_POINTS：将传入的顶点坐标作为单独的点绘制

   - GL_LINES：将传入的坐标作为单独线条绘制，ABCDEFG六个顶点，绘制AB、CD、EF三条线，如果点的个数是奇数，最后一个点将被忽略。
   - GL_LINE_STRIP条状/带状：将传入的顶点作为折线绘制，ABCD四个顶点，绘制AB、BC、CD三条线
   - GL_LINE_LOOP：将传入的顶点作为闭合折线绘制，ABCD四个顶点，绘制AB、BC、CD、DA四条线。

   - GL_TRIANGLES：将传入的顶点作为单独的三角形绘制，ABCDEF绘制ABC,DEF两个三角形
   - GL_TRIANGLE_STRIP：将传入的顶点作为三角条带绘制，ABCDEF绘制ABC,BCD,CDE,DEF四个三角形
   - GL_TRIANGLE_FAN扇形：将传入的顶点作为扇面绘制，ABCDEF绘制ABC、ACD、ADE、AEF四个三角形
2. first：第一个顶点元素的索引
3. count： 一共有多少个顶点

#+ATTR_latex: :width 800   #+ATTR_HTML: :width 800  #+ATTR_ORG: :width 800
[[file:webgl/drawarrays_mode.png]]

** glDrawElements(mode, count, type, const GLvoid * indices); 用EBO绑定顶点索引的方式绘制模型时，要用glDrawElements而不是glDrawArrays绘制图元
glDrawElements函数从当前绑定到GL_ELEMENT_ARRAY_BUFFER目标的EBO中获取索引
1. mode指定绘制图元的类型，和glDrawArrays的取值一致。
2. count一共有多少个顶点
3. type为EBO索引值的类型，只能是下列值之一：GL_UNSIGNED_BYTE, GL_UNSIGNED_SHORT, or GL_UNSIGNED_INT。
4. indices：指定索引在EBO缓冲区起始位置的偏移量

** glLoadIdentity()，glPushMatrix()，glPopMatrix()
- glLoadIdentity()的作用就是把当前矩阵设为为单位矩阵.
- glPushMatrix、glPopMatrix相当于堆栈里的入栈和出栈。 *Push起到保护环境、Pop起到恢复环境的作用* 。这2个函数可以嵌套使用。调用glPushMatrix就是把 当前矩阵做一个副本放入堆栈，然后不管你之后做了多少变换，这时调用glPopMatrix，当前矩阵就可以恢复到你调用glPushMatrix之前的那个状态。例如当前的 坐标系原点在电脑屏幕的左上方。现在调用glPushMatrix，然后再调用一堆平移、旋转代码等等，然后再画图。那些平移和旋转都是基于坐上角为原点进行变化的。 而且都会改变坐标的位置，经过了这些变化后，你的坐标肯定不再左上角了。如果想恢复怎么办？这时调用glPopMatrix从栈里取出一个“状态”，这个状态就是 你调用glPushMatrix之前的那个状态。
** glMatrixMode(GLenum mode); 设置当前矩阵是什么矩阵：
OpenGL里面的操作，很多是对矩阵的操作，比如位移，旋转，缩放。glMatrixMode就是用来指定接下来将要对那类矩阵进行操作，由参数mode来指定
- GL_MODELVIEW对模型视景矩阵操作: 接下来的语句描绘一个以模型为基础的适应，这样来设置参数，接下来用到的就是像gluLookAt()这样的函数
- GL_PROJECTION对投影矩阵操作: 就像照相一样，把3维物体投到2维平面上。这样，接下来的语句可以是跟透视相关的函数，如glFrustum()或gluPerspective()
- GL_TEXTURE是对纹理矩阵进行随后的操作

当我们设置了当前的矩阵后，接下来调用的openGL库函数必须确定是针对我们设定的这个当前矩阵的，不能张冠李戴。 例如，下面这样调用是错误的， 因为我们设置了 当前矩阵为模型视景矩阵，而gluPerspective是要对投影矩阵进行操作，那么计算机就会把模型矩阵当做投影矩阵，来与 gluPerspective指定的矩阵进行乘法运算，最终导致错误。
#+begin_src c++
glMatrixMode（GL_MODELVIEW ）；//设置当前矩阵为模型视景矩阵
gluPerspective(45.0f, (GLfloat)cx/(GLfloat)cy, 0.1f, 100.0f)；  //对图像进行透视投影，以将三维物体显示在二维平面上

#+end_src

** glTexParameteri(target, pname, param)配置纹理参数
将param的值赋给绑定到目标的纹理对象的pname参数上。默认每个纹理参数都有默认值，通常你可以不用手动显示的调用这个函数，使用默认值就可以。
- 第1个参数target： 指定纹理的类型，有两个值
  - gl.TEXTURE_2D二维纹理
  - gl.TEXTURE_CUBE_MAP立方体纹理
- 第2个参数pname：纹理参数的名字，决定了获取纹素颜色的方式；
  +  *放大方法* ：gl.TEXTURE_MAG_FILTER，当绘制范围比纹理本身大 时，如将16*16的纹理映射到32*32像素的空间时， *纹理的尺寸不够* ，该参数决定了如何填充这些放大的空隙。默认值：gl.LINEAR
  + *缩小方法* ：gl.TEXTURE_MIN_FILTER，当的绘制范围比 *纹理本身小* 时，如将32*32的纹理映射到16*16像素的空间时， *纹理的尺寸比需要的大* 了，需要剔除纹理图像中的部分像素。该参数决定了剔除的方法。默认：gl.NEAREST_MIPMAP_LINEAR
  + 水平填充方法：gl.TEXTURE_WRAP_S，如何对纹理图像左侧或者右侧的区域进行填充；默认值：gl.REPEAT
  + 垂直填充方法：gl.TEXTURE_WRAP_T，如何对纹理图像上方和下方的区域进行填充；默认值：gl.REPEAT
- 第3个参数param：是纹理参数的值：
  - 可以赋给 gl.TEXTURE_MAG_FILTER 和 gl.TEXTURE_MIN_FILTER 的值有2个
    1. gl.NEAREST: 使用原纹理上距离映射后像素中心最近的那个像素的颜色值，作为新像素的值。
    2. gl.LINEAR: 使用距离新像素中心最近的四个像素的颜色值的加权平均，作为新像素的值（和gl.NEAREST相比，该方法图像质量更好，但也会有较大的开销。）
  - 可以赋给 gl.TEXTURE_WRAP_S 和 gl.TEXTURE_WRAP_T 的值3个：
    1. gl.REPEAT: 平铺式的重复纹理
    2. gl.MIRRORED_REPEAT: 纹理镜像重复填充
    3. gl.CLAMP_TO_EDGE: 使用纹理边缘的像素填充

** void glfwSwapBuffers(GLFWwindow* window)交换缓冲区
GLFW窗口默认是双缓冲的，这意味着每个窗口有两个渲染缓冲区——前缓冲区和后缓冲区。 前缓冲区是正在显示的缓冲区，后缓冲区是即将显示的缓冲区。当整个帧已经被渲染时，缓冲器需要彼此交换，因此后缓冲器变为前缓冲器，反之亦然。

** void glfwSwapInterval(int interval) 设置缓冲区交换间隔，也就是需要等待显示器的Vsync刷新次数
- 参数 interval: 设置需要等待多少次 *屏幕的刷新次数vsync（其实就是，监视器实际的刷新频率里，要发生了多少次监视器刷新Vsync)* ，缓冲区才会交换。
  - 默认情况下，交换间隔为0, 则在调用glfwSwapBuffers时立即进行交换,而不等待屏幕刷新的到来。
  - 如果设成1，那就表示屏幕刷新1次时，才交换缓冲区。
屏幕撕裂现象Screen tearing: 就是当GPU往屏幕渲染的帧率大于屏幕刷新的帧率(监视器刷新帧率)，也就是说，当屏幕绘制（刷新）一帧到中间时， GPU已经向屏幕输送了好几帧，而屏幕会继续绘制（刷新），但这时用的数据是GPU向屏幕更新的数据。 这样就导致的屏幕撕裂的问题。 而解决这种问题的方式，设置交换间隔为1，开启 Vsync垂直同步，避免撕裂直到屏幕刷新完当前帧为止。
