[[https://webgpu.io/][WebGPU]]不但可以用于Web，作为WebGL后续发展的替代。它还可以用于原生平台，而且跨平台。相较于Metal和DX12，WebGPU的API和Vulkan的相似度最高。
- 谷歌和Mozilla合作，定义了一个用于原生平台的c接口 [[https://github.com/webgpu-native/webgpu-headers][webgpu.h]]，并同时给出了各自的实现。
- [[https://github.com/gfx-rs/wgpu][wgpu]] Mozilla的原生实现。firefox上的WebGPU实现，就是用这个wgpu来实现的。
- [[https://dawn.googlesource.com/dawn][dawn]] 谷歌的原生实现，Chrome的WebGPU实现，也是用dawn来实现的。

  #+begin_quote
  WebGPU规范副主席 Corentin Wallez， 他也是谷歌WebGUP实现小组的Leader，在19年DevFest上有个油管的视频介绍WebGPU不错：[[https://www.youtube.com/watch?v=EhWvqaRDz5s&list=LLDobcIfc2f6biSPC36-iQOg&index=2&t=0s][WebGPU: Next-generation 3D graphics on the web (DevFest 2019)]]
  #+end_quote



* 背面剔除Backface Culling: 早点丢弃那些被遮挡、观察者看不见背面，提高渲染速度。
当我们观察场景中对象时，一般只能以一定角度来观察，那么对象的某些面我们是看不到的，例如观察一个立方体，最多只能同时看到3个面，有时只能看到1个面，而绘制时如果不采取剔除背面的措施，则要绘制6个面，其中包括一些，我们根本看不到的面。开启背面剔除就是早点丢弃那些被遮挡、观察者看不见的背面，能明显改善渲染性能。
- 视锥剔除Frustum Culling非常的快(如果算法好的话)，是在渲染管线(Rendering Pipeline)之前进行的，不像背面剔除Backface Culling需要在渲染管线之后一个顶点一个顶点地计算。对于被剪裁掉的物体绘图引擎都不会将其送入显卡，因此视锥剔除对渲染速度有巨大的改善,毕竟什么都不渲染是最快的渲染.
- 哪个面是 *正面FrontFace或者背面Backface* ？是根据观察者的观察方向，使用顶点绕序(winding order)的方向来确定：从观察者看向屏幕的三角形， 习惯上的正面或者前面是指： *顶点以逆时针的顺序定义的三角形（wgpu::FrontFace::Ccw）* 。 想要剔除背面就是（wgpu::CullMode::Back）
  - ccw: counterclockwise 逆时针
  - cw: clockwise 顺时针
    #+ATTR_latex: :width 650   #+ATTR_HTML: :width 650  #+ATTR_ORG: :width 650
    [[file:WebGPU/winding_order.jpg]]


* 深度偏移Depth Bias
通过给多边形增加一个z方向深度偏移(depth bias，z_bias),使3D空间的共面多边形看起来好像并不共面，以便它们能够被正确渲染。 这种技术是很有用的， 例如要渲染投射在墙上的阴影，这时候墙和阴影共面，如果没有深度偏移，先渲染墙，再渲染阴影，由于depth test,阴影可能不能正确显示。我们给墙设置一个深度偏移，使它增大，例如z增加0.01，先渲染墙，再渲染阴影，则墙和阴影可以正确的显示。
- depthBiasSlopeFactor为启用深度偏移时，添加到片段深度倾斜slope计算中的值
- depthBiasClamp为深度偏移的最大值（或最小值），可以在启用深度偏置时添加到片段的深度


* ColorAttachmen颜色附件
loadOp和storeOp表示渲染前和渲染后要做的动作。如下例，渲染前先清屏(Clear)，我们想让渲染后的图像显示到屏幕上，所以将storeOp设置为保存Store
#+begin_src c++
load_op: wgpu::LoadOp::Clear    // 渲染前先清屏(Clear)
store_op: wgpu::StoreOp::Store  // 想让渲染后的图像显示到屏幕上，所以将storeOp设置为保存Store
clear_color: wgpu::Color {r: 0.1,  g: 0.2,  b: 0.3,  a: 1.0,} // 定义清屏的颜色

#+end_src


* 纹理texture
纹理映射也叫纹理贴图：是一种将纹理图像应用于物体表面的技术，就是把图像贴到构成物体表面的多边形上去，就像该图像是一种贴画纸或玻璃纸附着于物体的表面上。主要有：法线贴图normal map、凹凸贴图bump map、高光贴图specular map和漫反射贴图diffuse map。

什么是纹理过滤呢？纹理映射的过程会随着目标点距离相机远近的不同，而占用屏幕不同大小范围的像素，例如一个三角面在距离相机20m时占用100个屏幕像素，当三角面离相机更远时会看起来更小，此时可能占用20个屏幕像素，但是在两种情况下这个三角面使用的纹理贴图的大小是不变的。所以一个像素通常不直接对应于一个纹理单元。必须用某种形式的滤波来确定像素的最佳颜色。滤波不足或不正确，贴图就会变得模糊或发生错位，马赛克。
- *纹理要放大TEXTURE_MAG_FILTER* ：将16*16的纹理映射到32*32像素空间时， 纹理的尺寸不够，纹理要被放大，导致一个纹理单元对应着多个象素。
- *纹理要缩小TEXTURE_MIN_FILTER* ：将32*32的纹理映射到16*16像素空间， 纹理的尺寸比需要的大了，需要剔除纹理图像中的部分像素，导致一个象素对应多个纹理单元。

TEXTURE_MAG_FILTER 、 TEXTURE_MIN_FILTER 和 mipmap_filter 的取值有2个
- NEAREST: 使用原纹理上距离映射后像素中心最近的那个像素的颜色值，作为新像素的值。
- LINEAR: 使用距离新像素中心最近的四个像素的颜色值的加权平均，作为新像素的值。和NEAREST相比，该方法图像质量更好，但有较大的开销。

地址模式address_mode 决定了当纹理采样器sampler得到的纹理坐标位于纹理之外时该怎么做。
- CLAMP_TO_EDGE: 使用纹理边缘的像素填充，纹理外部的任何纹理坐标都将返回纹理边缘上最近的像素的颜色。
- REPEAT: 平铺式的重复纹理
- MIRRORED_REPEAT: 纹理镜像重复填充

  #+end_quote
** 纹理Mipmap，用于纹理被缩小的情况，属于三线性过滤。
*纹理mipmap* 用于纹理被缩小的情况，属于三线性过滤，它 的基本思路是，对远处的东东，用尺寸较小、分辨率较低的纹理； 对近处的东东，用尺寸交大、分辨率较高的纹理。 因为在三维世界中, 显示一张图的大小与摄象机机距离模型的远近位置有关,近的地方, 图片就大一些,远的地方图片就会小一些。 当摄像机较 远的时候，用精细的贴图玩家也看不见， 而且还浪费资源，此时完全可以用更小的贴图。
- mipmap的关键是预先将贴图压缩成很多逐渐缩小的图片, 按照2的倍数 *每次缩小一半直到1X1* ， 把缩小的图都 *预先存储* 起来。例如 一张64*64的图片,会产生64*64, 32*32,16*16,8*8,4*4, 2*2,1*1的7张图片,当屏幕上 需要绘制像素点 为20*20 时，程序只是利用 32*32 和 16*16 这两张图片来计算 出即将显示为 20*20 大小的一个图片，这比单独利用 32*32 的那张原始片计算出来的图片效果要好得多，速度也更快.
- mip level： 一系列缩略图的编号即为mip level。 *level 0为原图* ，之后的每一个level 都比上一个level长宽缩减到一半， 也就是按照2的倍数进行缩小 直到1X1。 Mip层0是最初的图像，之后的mip层被称为mip链。

** 各向异性纹理过滤 anisotropic filtering：纹理在x坐标方向和在y坐标方向缩放的比例不一样
假设Px为纹理在x坐标方向上的缩放的比例因子；Py为纹理在y坐标方向上的缩放的比例因子；Pmax为Px和Py中的最大值；Pmin为Px和Py中的最小值。当Pmax/Pmin等于1时，也就是说Px等于Py，是对正方形区域里行采样，纹理的缩放是各向同性的；但是如果Pmax/Pmin不等于1而是大于1，Px不等于Py，也就是说纹理在x坐标方向和在y坐标方向缩放的比例不一样，纹理的缩放是各向异性的，Pmax/Pmin代表了各向异性的程度。

** 纹理坐标texture coordinates：纹理通常来说就是一张图片，纹理坐标是二维的
- 纹理坐标：原点（0.0， 0.0）在左下角，  x轴正向朝右， y轴正向朝上。坐标值和图像大小无关，不管是128*128还是128*256的图像，其右上角坐标始终是（1.0，1.0）
- 纹理坐标就是纹理图像上的坐标，纹理坐标是二维的，为了和广泛使用的xy坐标区分开来， 习惯用s和t来命名纹理坐标（st坐标系统）。
- 不论图片尺寸有多大，长和宽各是多少，强制规定了纹理坐标总是从0到1之间取值。
- 通过纹理坐标可以在纹理图像上获取纹素的颜色。

#+ATTR_latex: :width 400   #+ATTR_HTML: :width 400  #+ATTR_ORG: :width 400
[[file:webgl/texture_coord.png]]


* 渲染通道 Render pass  &  多通道渲染multipass rendering
现实场景中，如果想获得逼真的渲染效果，往往需要考虑阴影，照明和反射。 每一个都需要大量的计算，通常都是在它们各自的渲染通道Render pass中完成。最后再把它们的渲染结果组合形成最终的效果。

为什么需要多通道渲染呢multipass rendering？在源头就将阴影，照明和反射这些信息独立开来，这样在合成的时候我们就可以有更多的控制空间和选择余地了。 简单的场景一般只要一个渲染通道
