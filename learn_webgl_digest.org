* WebGL和画布canvas
WebGL使用HTML5中新引入的<canvas>标签来定义绘图区域；传统的<img>标签只能用来显示图片，不能进行实时绘制和渲染；<canvas>允许Javascript动态的绘制图形，没有WebGL, Javascript只能在<canvas>绘制二维图形，有了WebGL,就可以在上面绘制三维图形。
#+ATTR_latex: :width 800   #+ATTR_HTML: :width 800  #+ATTR_ORG: :width 800
[[file:webgl/webgl_opengl.png]]

- 2011年3月发布基于OpenGL ES 2.0的 WebGL 1.0;  2017年1月发布基于OpenGL ES 3.0的WebGL 2.0。
- 截止2019年12月，iOS和Android上的浏览器都已经支持WebGL 1.0, 但都还不支持WebGL 2.0。 PC上，Chrome和firefox都支持WebGL 2.0, safari只支持WebGL 1.0
- 在浏览器输入 https://webglreport.com/ 可查看该浏览器对WebGL的支持情况。
- WebGL渲染过程
#+ATTR_latex: :width 800   #+ATTR_HTML: :width 800  #+ATTR_ORG: :width 800
[[file:webgl/webgl_pipeline.png]]


* 图像管线Graphics pipeline： 顶点着色器、光栅化、片元着色器
- vertex shader顶点着色器（确定顶点的位置）：针对每个顶点都执行一次该着色器（逐顶点操作），它最重要的功能是执行顶点的坐标变换，输出的是归一化后的坐标NDC（-1.0， 1.0）。顶点指的是二维或三维空间总的一个点的位置坐标。
- primitive assembly图元装配：将孤立的顶点装配成图元，图元类型由gl.drawArrays函数的第1个参数决定：GL_POINTS、GL_LINE...、GL_TRIANGLE...
- rasterizaiton光栅化（生成片元fragment）：显示在屏幕上的图元，实际上是由屏幕上离散的像素组成的。所以光栅化其实就是将图元primitive转换成屏幕上的像素（片元fragment），屏幕外（视椎体外）不可见的片元将被丢弃。
  - 片元指的是屏幕上的一个像素，包括像素的位置坐标（gl_FragCoord）、颜色和其它信息。
- fragment shader片元着色器（确定片元的颜色）：针对每个片元都执行一次该着色器（逐片元操作）来计算每个片元（像素）的颜色值，并将每个片元的颜色值写入颜色缓冲区中，等到图形中所有的片元处理完毕画布上就得到了最后的图像。
- GLSL: OpenGL着色语言（OpenGL Shading Language）是用来在OpenGL中进行着色编程的语言
#+ATTR_latex: :width 800   #+ATTR_HTML: :width 800  #+ATTR_ORG: :width 800
[[file:webgl/webgl_pipeline2.png]]


* 颜色缓冲区Color Buffer
- gl.clear(gl.COLOR_BUFFER_BIT)  在绘制开始前，经常见到调用函数 *清空画布* 的代码gl.clear(gl.COLOR_BUFFER_BIT)，清空画布的绘图区实际上就是用之前定义好的背景颜色将颜色缓冲的的颜色清除。
- 颜色缓冲区中存放着需要显示到画布上的像素的颜色数据， 它属于帧缓存的一部分，与深度缓存、模板缓存等一起决定着最终画布上图像的显示信息。


* 在canvas绘图的4个步骤
** 1、在html中定义canvas，并用id属性为其指定唯一标识符；加载JS文件，同时在<body>的onload属性指定JS执行的入口函数
#+begin_src html
<!DOCTYPE html>
<html lang="en">
  <head> <meta charset="utf-8" /> <title>Draw a blue rectangle (canvas version)</title>  </head>

  <body onload="main()"> <!-- 指定执行JS的入口函数 -->
    <canvas id="webgl" width="400" height="400">  Please use a browser that supports "canvas" </canvas> <!-- 定义canvas，并用id属性为其指定唯一标识符, 也指定了画布的宽高； -->
    <script src="DrawRectangle.js"></script>       <!-- 加载JS文件 -->
  </body>
</html>
#+end_src

** 2、通过id标识符，获取<canvas>元素
** 3、请求绘图上下文context
** 4、通过绘图上下文调用绘图函数

** 例子1：清空绘图背景色

#+begin_src javascript
// DrawTriangle.js (c) 2012 matsuda
function main() {               // JS函数入口
    var canvas = document.getElementById('webgl'); // 通过id标识符，获取<canvas>元素
    if (!canvas) {
        console.log('Failed to retrieve the <canvas> element');
        return false;
    }

    var gl = canvas.getContext('webgl'); // 用webgl或expeimental-webgl请求WebGL绘图上下文。

    // 用指定的黑色，清空绘图区域
    gl.clearColor(0.0, 0.0, 0.0, 1.0); // 指定清空画布的颜色为黑色。 颜色的取值从0.0到1.0。前面3个参数分别是rgb的值。最后一个参数是透明度a，它的取值在0.0透明---到1.0不透明之间。
    gl.clear(gl.COLOR_BUFFER_BIT);     // 用上面设置的clearColor清空绘图区域。opengl有多个缓冲区：颜色缓冲区COLOR_BUFFER_BIT、深度缓冲区DEPTH_BUFFER_BIT、模版缓冲区STENCIL_BUFFER_BIT。清空绘图区域实际上是清空颜色缓冲区color buffer， 所以这里传递的参数是COLOR_BUFFER_BIT
}
#+end_src

** 例子2: 绘制一个点
#+begin_src javascript
// vertex shader顶点着色器进行的是逐顶点的操作。顶点指的是二维或三维空间总的一个点的位置坐标。
var VSHADER_SOURCE =
    'void main() {\n' +
    '  gl_Position = vec4(0.0, 0.0, 0.0, 1.0);\n' + // gl_Position是内置变量，用来表示一个顶点的位置坐标。
    '  gl_PointSize = 10.0;\n' +                    // gl_PointSize也是内置变量，用来表示点的大小： 这里把每个点设为10个像素的大小
    '}\n';

// fragment shader片元着色器的作用就是处理片元，使其显示在屏幕上，它进行的也是逐片元的操作。 片元指的是显示在屏幕上的一个像素，包括像素的位置、颜色和其它信息。
var FSHADER_SOURCE =
    'void main() {\n' +
    '  gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);\n' + // gl_FragColor是片元着色器唯一的内置变量，它控制这像素在屏幕上的最终颜色RGBA，这里设为红色
    '}\n';

function main() {
    var canvas = document.getElementById('webgl'); // 获取canvas元素

    var gl = getWebGLContext(canvas); // 获取webgl的绘图上下文
    if (!gl) {
        console.log('Failed to get the rendering context for WebGL');
        return;
    }

    if (!initShaders(gl, VSHADER_SOURCE, FSHADER_SOURCE)) { // 初始化着色器
        console.log('Failed to intialize shaders.');
        return;
    }

    // 用指定的黑色，清空绘图区域
    gl.clearColor(0.0, 0.0, 0.0, 1.0); // 指定清空画布的颜色为黑色。 颜色的取值从0.0到1.0。前面3个参数分别是rgb的值。最后一个参数是透明度a，它的取值在0.0透明---到1.0不透明之间。
    gl.clear(gl.COLOR_BUFFER_BIT);     // 用上面设置的clearColor清空绘图区域。opengl有多个缓冲区：颜色缓冲区COLOR_BUFFER_BIT、深度缓冲区DEPTH_BUFFER_BIT、模版缓冲区STENCIL_BUFFER_BIT。清空绘图区域实际上是清空颜色缓冲区color buffer， 所以这里传递的参数是COLOR_BUFFER_BIT

    // drawArrays(mode, first, count) 触发绘制开始执行：先把缓冲区中的数据传递给attribute|uniform|varying变量， 然后着色器开始执行。先逐顶点的执行顶点着色器vertex shader...再逐片元的执行片元着色器fragment shader。
    // count被设为1表示只绘制一个点，所以drawArrays触发顶点着色器执行1次：它将vec4(0.0, 0.0, 0.0, 1.0)赋值给gl_Position，将值10.0赋给gl_PointSize.
    // 一旦顶点着色器执行完后，片元着色器就开始执行，调用main()函数：将颜色值红色 vec4(1.0, 0.0, 0.0, 1.0)赋给gl_FragColor
    // 最终的结果就是：1个 红色的 10个像素大的点 被绘制在了(0.0, 0.0, 0.0, 1.0）处，也就是canvas的中间。
    gl.drawArrays(gl.POINTS, 0, 1); // gl.POINTS表示绘制点; 0 表示从第一个顶点开始绘制； 1 表示只有一个顶点，所以drawArrays触发顶点着色器执行1次
}
#+end_src


* WebGL坐标、纹理坐标
** canvas的坐标
- 原点（0，0）在左上角， x轴正向朝右， y轴正向朝下。例如：定义的canvas宽高（400，400）， 在用如下代码绘制的矩形fillRect(120, 10, 150, 150)，效果如下图所示：
#+begin_src javascript
ctx.fillStyle = 'rgba(0, 0, 255, 1.0)'; // Set color to blue
ctx.fillRect(120, 10, 150, 150);        // Fill a rectangle with the color
#+end_src
#+ATTR_latex: :width 300   #+ATTR_HTML: :width 300  #+ATTR_ORG: :width 300
[[file:webgl/canvas_coord.png]]

** 浏览器客户区坐标 client area
- 在浏览器，鼠标点击位置的坐标，是一个基于浏览器客户区的坐标值（client area）。它和canvas的坐标关系如下图所示：
#+ATTR_latex: :width 800   #+ATTR_HTML: :width 800  #+ATTR_ORG: :width 800
[[file:webgl/browser_coord.png]]

** WebGL/OpenGL坐标 也叫 右手坐标系(Right-handed Coordinate System)： 伸开右手，大拇指指向X轴正方向，食指指向Y轴正方向，其他三个手指指向Z轴正方向。
- 当我们看向屏幕，原点（0.0，0.0，0.0）在屏幕的中间，X轴正向朝右， Y轴正向朝上，Z轴垂直于屏幕正向朝外（从屏幕指向你的后面）。

#+ATTR_latex: :width 700   #+ATTR_HTML: :width 700  #+ATTR_ORG: :width 700
[[file:webgl/webgl_coord.png]]

** 纹理坐标texture coordinates：纹理通常来说就是一张图片
- 纹理坐标：原点（0.0， 0.0）在左下角，  x轴正向朝右， y轴正向朝上。坐标值和图像大小无关，不管是128*128还是128*256的图像，其右上角坐标始终是（1.0，1.0）
- 纹理坐标就是纹理图像上的坐标，纹理坐标是二维的，为了和广泛使用的xy坐标区分开来， 习惯用s和t来命名纹理坐标（st坐标系统）。
- 不论图片尺寸有多大，长和宽各是多少，强制规定了纹理坐标总是从0到1之间取值。
- 通过纹理坐标可以在纹理图像上获取纹素的颜色。

#+ATTR_latex: :width 400   #+ATTR_HTML: :width 400  #+ATTR_ORG: :width 400
[[file:webgl/texture_coord.png]]


* 从app传递数据给着色器：attribute变量、uniform变量和varying变量
** attribute变量
- attribute变量：只能在vertex shader中使用的变量, 一般用来表示顶点的数据如：顶点坐标，纹理坐标，顶点颜色等。
- 在顶点着色器里，必须要把attribute变量声明为一个全局变量。
- 应用程序通过glGetAttribLocation函数来获得某个attribute 变量存储位置， 然后通过glVertexAttrib**函数赋值。

** uniform变量
- 用来向vertex或fragment着色器中传递不变的数据，就像C语言里的const常量，它不能被shader程序修改（shader只能用，不能改）。如果想从app传递数据给片元着色器，就要使用uniform变量。
- 如果uniform变量在vertex和fragment着色器两者之间的声明方式完全一样，则它可以在vertex和fragment共享使用。相当于一个被vertex和fragment shader共享的全局变量
- uniform变量一般用来表示：变换矩阵，材质，光照参数和颜色等信息。
- 应用程序通过glGetUniformLocation函数函数来获得存储位置，再通过函数glUniform**（）函数赋值

** varying变量
- varying变量：用来从顶点着色器向片元着色器传递数据。一般vertex shader修改varying变量的值，然后fragment shader使用该varying变量的值。只要varying变量在顶点着色器和片元着色器中的声明是一致的（类型和名字都要相同）就可以了。
- 应用程序不能访问或使用此变量。所以一般的做法是：应用程序先把数据传给顶点着色器的attribute变量， 然后attribute变量再把值传给varying变量， 最终fragmnet shader就可以使用varying 变量的值。

** 例子：绘制一个点， 用attribute变量，传递一个顶点坐标给顶点着色器
#+begin_src javascript
// Vertex shader program
var VSHADER_SOURCE =
    'attribute vec4 a_Position;\n' + // - attribute变量：被用来从app向顶点着色器传递数据。只有顶点着色器vertex shader能使用它，所以一般用来传递和顶点相关的数据。在顶点着色器里，必须把attribute变量声明为全局变量。

    'void main() {\n' +
    '  gl_Position = a_Position;\n' + // 通过attribute变量， 把顶底坐标值赋给 gl_Position。所以只要在app里动态调整attribute变量的值，就可以修改顶点着色器的坐标。
    '  gl_PointSize = 10.0;\n' +
    '}\n';

// Fragment shader program
var FSHADER_SOURCE =
    'void main() {\n' +
    '  gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);\n' +
    '}\n';

function main() {
    var canvas = document.getElementById('webgl');

    var gl = getWebGLContext(canvas);
    if (!gl) {
        console.log('Failed to get the rendering context for WebGL');
        return;
    }

    if (!initShaders(gl, VSHADER_SOURCE, FSHADER_SOURCE)) {
        console.log('Failed to intialize shaders.');
        return;
    }

    var a_Position = gl.getAttribLocation(gl.program, 'a_Position'); // 获取attribute变量的存储位置
    if (a_Position < 0) {
        console.log('Failed to get the storage location of a_Position');
        return;
    }

    gl.vertexAttrib3f(a_Position, 0.0, -0.5, 0.0); // 给顶点着色器的attribute变量赋值

    gl.clearColor(0.0, 0.0, 0.0, 1.0);
    gl.clear(gl.COLOR_BUFFER_BIT);     // 用上面设置的clearColor清空绘图区域。opengl有多个缓冲区：颜色缓冲区COLOR_BUFFER_BIT、深度缓冲区DEPTH_BUFFER_BIT、模版缓冲区STENCIL_BUFFER_BIT。清空绘图区域实际上是清空颜色缓冲区color

    gl.drawArrays(gl.POINTS, 0, 1);
}
#+end_src
** 例子： 在鼠标点击位置绘制点，使用attribute变量传递鼠标点击位置给顶点着色器；用uniform变量传递颜色给片元着色器
#+begin_src javascript
// Vertex shader program
var VSHADER_SOURCE =
    'attribute vec4 a_Position;\n' + //  声明attribute 变量
    'void main() {\n' +
    '  gl_Position = a_Position;\n' +
    '  gl_PointSize = 10.0;\n' +
    '}\n';

// Fragment shader program
var FSHADER_SOURCE =
    'precision mediump float;\n' +
    'uniform vec4 u_FragColor;\n' +  // 声明uniform变量。 顶点着色器才能使用attribute变量， 如果想从app传递数据给片元着色器，就要使用uniform变量。
    'void main() {\n' +
    '  gl_FragColor = u_FragColor;\n' +
    '}\n';

function main() {
    var canvas = document.getElementById('webgl');

    var gl = getWebGLContext(canvas);
    if (!gl) {
        console.log('Failed to get the rendering context for WebGL');
        return;
    }

    if (!initShaders(gl, VSHADER_SOURCE, FSHADER_SOURCE)) {
        console.log('Failed to intialize shaders.');
        return;
    }

    var a_Position = gl.getAttribLocation(gl.program, 'a_Position'); // 获取attribute变量的存储位置
    if (a_Position < 0) {
        console.log('Failed to get the storage location of a_Position');
        return;
    }

    var u_FragColor = gl.getUniformLocation(gl.program, 'u_FragColor'); // 获取uniform变量的存储位置
    if (!u_FragColor) {
        console.log('Failed to get the storage location of u_FragColor');
        return;
    }

    canvas.onmousedown = function(ev){ click(ev, gl, canvas, a_Position, u_FragColor) }; // 注册鼠标点击时的回调函数

    gl.clearColor(0.0, 0.0, 0.0, 1.0);

    gl.clear(gl.COLOR_BUFFER_BIT);     // 用上面设置的clearColor清空绘图区域。opengl有多个缓冲区：颜色缓冲区COLOR_BUFFER_BIT、深度缓冲区DEPTH_BUFFER_BIT、模版缓冲区STENCIL_BUFFER_BIT。清空绘图区域实际上是清空颜色缓冲区color
}

var g_points = [];  // 记录所有鼠标点击位置的坐标
var g_colors = [];  // The array to store the color of a point
function click(ev, gl, canvas, a_Position, u_FragColor) {
    var x = ev.clientX;   //  鼠标点击位置的坐标，是一个基于浏览器客户区的坐标值（client area）
    var y = ev.clientY;   //  下面还要做坐标转换：client area  --》 canvas坐标  --》 webgl的归一化设备坐标
    var rect = ev.target.getBoundingClientRect(); // 获取canvas的矩形区域

    // （x - rect.left）从浏览器客户区坐标转换成canvas坐标。  ((x - rect.left) - canvas.width/2) 获得把canvas的原点移到中心点的坐标。 再除以(canvas.width/2）完成归一化。
    x = ((x - rect.left) - canvas.width/2)/(canvas.width/2); // 把鼠标点击时的坐标转换为opengl的归一化坐标（-1.0，1.0）
    y = (canvas.height/2 - (y - rect.top))/(canvas.height/2); // (y - rect.top) 从浏览器客户区坐标转换成canvas坐标。 (canvas.height/2 - (y - rect.top))获得把canvas的原点移到中心点的坐标

    g_points.push([x, y]);                 // 要把鼠标每次点击的位置都记录下来（基于webgl的归一化的坐标）？而不是仅仅记录最近一次鼠标点击的位置。

    if (x >= 0.0 && y >= 0.0) {      // 不同的区域设置不同的颜色， 第一象限
        g_colors.push([1.0, 0.0, 0.0, 1.0]);  // Red
    } else if (x < 0.0 && y < 0.0) { // 第三象限
        g_colors.push([0.0, 1.0, 0.0, 1.0]);  // Green
    } else {                         // 其它
        g_colors.push([1.0, 1.0, 1.0, 1.0]);  // White
    }

    gl.clear(gl.COLOR_BUFFER_BIT); //  这行很重要。每次绘制完成之后，颜色缓冲区都会被重置，所以这里要明确的用我们自己设定的clear color来清空画布。

    var len = g_points.length;      // 绘制操作实际上是在颜色缓冲区color buffer中进行，绘制结束后系统将缓冲区中的内容显示在屏幕上，然后颜色缓冲区就会被重置，其中的内容会丢失
    for(var i = 0; i < len; i++) {  // 因此我们有必要将鼠标每次点击的位置都记录下来，鼠标每次点击之后，程序都重新绘制了所有的点，从第一次点击到最近的一次。
        var xy = g_points[i];         // 比如第1次点击鼠标，绘制第1个点；。。。 第3次点击鼠标，绘制第1、2和第3个点；以此类推
        var rgba = g_colors[i];

        gl.vertexAttrib3f(a_Position, xy[0], xy[1], 0.0); // 通过赋值给attribute变量， 把值传递给着色器
        gl.uniform4f(u_FragColor, rgba[0], rgba[1], rgba[2], rgba[3]); // 通过赋值给uniform变量，把颜色值传递给片元着色器的内置变量 u_FragColor
        gl.drawArrays(gl.POINTS, 0, 1);                                // 触发绘制
    }
}
#+end_src


* 缓冲对象buffer object
- 可以预先在缓冲对象中保存所有想要绘制的顶点数据，然后一次性将多个顶点数据的传给着色器，避免多次传输，提高效率。需要5个步骤：创建、绑定、填充、配置、激活

  1) 创建缓冲区对象 vertexBuffer = gl.createBuffer()
    
  2) 把缓冲区对象绑定到目标区域 gl.bindBuffer(gl.ARRAY_BUFFER | gl.ELEMENT_ARRAY_BUFFER, vertexBuffer)。
     - 目标区域gl.ARRAY_BUFFER表示缓冲区对象中包含的是顶点的数据。 gl.ELEMENT_ARRAY_BUFFER表示缓冲区对象中包含了顶点的索引值
       
  3) 向缓冲区对象写入数据 gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW) 将第2个参数vertices数组中的数据写入目标区域gl.ARRAY_BUFFER所对应的缓冲区（其实就是上一步绑定的缓冲区）
     - GL_STATIC_DRAW：表示该缓存区不会被修改； GL_DyNAMIC_DRAW：表示该缓存区会被周期性更改；GL_STREAM_DRAW：表示该缓存区会被频繁更改；

  4) 把缓冲区对象分配给attribute变量  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0);
     1. 第1个参数location：指定attribute变量， 这里是a_Position
     2. 第2个参数size：每个顶点的分量个数（1到4）， 这里是2；
     3. 第3个参数type：分量的数据类型，这里是gl.FLOAT
     4. 第4个参数normalize：false数据不需要做归一化处理；
     5. 第5个参数stride: 指定相邻两个顶点间间隔的字节数，这里是0。0表示相邻两个顶点是紧密排列的，OpenGL将自动推算出stride的值。
        - stride是相对于一组属性来说的，而不是对于属性的每一个成分来说的。以具有3个分量的顶点属性为例，有x、y、z三个成分，将x、y、z看做一组，stride是每一组之间的步幅。
     6. 第6个参数offset：指定顶点在缓冲区起始位置的偏移量，这里是0
       
     - gl.vertexAttrib3f(a_Position, 0.0, -0.5, 0.0)  *一次只能向attribute变量传输1个顶点的数据* 顶点数据多时，要传输多次，效率低。
     - gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0) 可以 *一次性将整个缓冲区对象（多个顶点数据）传给着色器的attribute变量* , 效率高很多

  5) 激活attribute变量，使顶点着色器能够访问缓冲区的数据。 gl.enableVertexAttribArray(a_Position)
     - 注意：只有遇到函数调用gl.drawArrays(mode, first, count)才会真正开始触发把缓冲区的数据传递给着色器变量

- gl.drawArrays(mode, first, count) 触发绘制开始执行：先把缓冲区中的数据传递给attribute|uniform|varying变量， 然后着色器开始执行。先逐顶点的执行顶点着色器vertex shader...再逐片元的执行片元着色器fragment shader。


** 例子：绘制3个独立的点或一个三角形，使用缓冲区对象一次性把这3个顶点传给attribute变量
#+begin_src javascript
// Vertex shader program
var VSHADER_SOURCE =
    'attribute vec4 a_Position;\n' + // attribute 变量
    'void main() {\n' +
    '  gl_Position = a_Position;\n' +
    '  gl_PointSize = 10.0;\n' +
    '}\n';

// Fragment shader program
var FSHADER_SOURCE =
    'void main() {\n' +
    '  gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);\n' +
    '}\n';

function main() {
    var canvas = document.getElementById('webgl');

    var gl = getWebGLContext(canvas);
    if (!gl) {
        console.log('Failed to get the rendering context for WebGL');
        return;
    }

    if (!initShaders(gl, VSHADER_SOURCE, FSHADER_SOURCE)) {
        console.log('Failed to intialize shaders.');
        return;
    }

    // 使用缓冲对象向顶点着色器一次性传输多个（3个）顶点数据。
    var n = initVertexBuffers(gl); // 创建顶点缓冲对象
    if (n < 0) {
        console.log('Failed to set the positions of the vertices');
        return;
    }

    gl.clearColor(0, 0, 0, 1);
    gl.clear(gl.COLOR_BUFFER_BIT);

    // 遇到函数调用gl.drawArrays(mode, first, count)才会真正开始触发把缓冲区的数据传递给着色器变量
    gl.drawArrays(gl.POINTS, 0, n); // n的值是3，代表有3个顶点，所以虽然该函数仅调用了一次，但顶点着色器会被触发执行3次。
    // gl.drawArrays(gl.TRIANGLES, 0, n); // gl.TRIANGLES表示绘制三角形：从缓冲区第一个顶点开始，执行顶点着色器3次（n为3），用这3个点绘制出一个三角形。

}

// 使用缓冲对象向顶点着色器一次性传输多个（3个）顶点数据。
function initVertexBuffers(gl) {
    var vertices = new Float32Array([
        0.0, 0.5,   -0.5, -0.5,   0.5, -0.5
    ]);
    var n = 3; // 顶点的数量是 3个

    var vertexBuffer = gl.createBuffer(); // 创建缓冲区对象
    if (!vertexBuffer) {
        console.log('Failed to create the buffer object');
        return -1;
    }

    gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer); // 绑定缓冲区对象到目标区域。目标区域gl.ARRAY_BUFFER表示缓冲区对象中包含的是顶点的数据。 gl.ELEMENT_ARRAY_BUFFER表示缓冲区对象中包含了顶点的索引值
    gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW); // 向缓冲区对象写入数据，将第2个参数vertices数组中的数据写入目标区域gl.ARRAY_BUFFER所对应的缓冲区（其实就是上一步绑定的缓冲区）

    var a_Position = gl.getAttribLocation(gl.program, 'a_Position'); // 获取attribute变量的存储位置
    if (a_Position < 0) {
        console.log('Failed to get the storage location of a_Position');
        return -1;
    }
    // gl.vertexAttrib3f(a_Position, 0.0, -0.5, 0.0)  *一次只能向attribute变量传输1个顶点的数据* 顶点数据多时，要传输多次，效率低。
    // gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0) 可以 *一次性将整个缓冲区对象（多个顶点数据）传给着色器的attribute变量* , 效率高很多
    // 本例stride的值是0，0表示相邻两个顶点是紧密排列的，OpenGL将自动算出stride的值。这里我们也可以直接手动改成8，因为2个float表示一个顶点的属性，2个float就是8个byte
    gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0); // 参数2表示每个顶点的分量个数（1到4）；false数据不需要做归一化处理；0表示相邻两个顶点是紧密排列的，OpenGL将自动算出stride的值。0指定顶点在缓冲区起始位置的偏移量。

    gl.enableVertexAttribArray(a_Position); // 激活attribute变量，使顶点着色器能够访问缓冲区的数据。

    return n;
}
#+end_src


* 函数详解glDrawArrays(GLenum mode, GLint first, GLsizei count) : 触发绘制开始执行》缓冲区数据传递给着色器变量》着色器执行绘制基本图元
- gl.drawArrays(mode, first, count) 触发绘制开始执行：先把缓冲区中的数据传递给attribute|uniform|varying变量， 然后着色器开始执行。先逐顶点的执行顶点着色器vertex shader...再逐片元的执行片元着色器fragment shader。
- WebGL可以绘制的3种基本图元是：点、线、三角形。其它的图形都是由这3种基本图元组成。

1. GLenum mode绘图模式：需要绘制的图元类型
   - GL_POINTS：将传入的顶点坐标作为单独的点绘制

   - GL_LINES：将传入的坐标作为单独线条绘制，ABCDEFG六个顶点，绘制AB、CD、EF三条线，如果点的个数是奇数，最后一个点将被忽略。
   - GL_LINE_STRIP条状/带状：将传入的顶点作为折线绘制，ABCD四个顶点，绘制AB、BC、CD三条线
   - GL_LINE_LOOP：将传入的顶点作为闭合折线绘制，ABCD四个顶点，绘制AB、BC、CD、DA四条线。

   - GL_TRIANGLES：将传入的顶点作为单独的三角形绘制，ABCDEF绘制ABC,DEF两个三角形
   - GL_TRIANGLE_STRIP：将传入的顶点作为三角条带绘制，ABCDEF绘制ABC,BCD,CDE,DEF四个三角形
   - GL_TRIANGLE_FAN扇形：将传入的顶点作为扇面绘制，ABCDEF绘制ABC、ACD、ADE、AEF四个三角形
2. GLint first：第一个顶点元素的索引
3. GLsizei count： 一共有多少个顶点

#+ATTR_latex: :width 800   #+ATTR_HTML: :width 800  #+ATTR_ORG: :width 800
[[file:webgl/drawarrays_mode.png]]


* 向量: 既有方向又有大小的量
- 向量表示的是方向，起始于何处并不会改变它的值，没有固定的起点，只要方向相同，大小相等，就认为两向量是相同的，但为了用数值坐标来表示向量，习惯将起始点放到原点（0，0，0）。下图可以看到向量v和w是相等的，尽管他们的起始点不同。
- 单位向量(Unit Vector)：它的长度是1，如果只关心方向不关心长度的时候，单位向量特别有用。比如，在计算光照模型时，我们往往需要得到顶点的法线方向和光源方向，此时我们不关心这些向量有多长
#+ATTR_latex: :width 250   #+ATTR_HTML: :width 250  #+ATTR_ORG: :width 250
[[file:webgl/vectors.png]]
** 向量与标量运算: +，-，·或÷，其中·是乘号。注意－和÷运算时不能颠倒（标量-/÷向量），因为颠倒的运算是没有定义的。
#+begin_quote
标量(Scalar)只是一个数字。当把一个向量加/减/乘/除一个标量，我们可以简单的把向量的每个分量分别和这个标量进行相应的运算。对于加法来说会像这样:
#+end_quote
#+ATTR_latex: :width 600   #+ATTR_HTML: :width 600  #+ATTR_ORG: :width 600
[[file:webgl/vector_add.png]]

** 向量间加减：对应位置的值可以组合而产生一个新向量
- 公式：u + v = < u.x , u.y  > + < v.x , v.y > = < u.x + v.x , u.y + v.y > 即将一个向量中的每一个分量加上另一个向量的对应分量
#+begin_quote
向量的加法满足平行四边形法则和三角形法则. 具体地，两个向量 a和b相加，得到的是另一个新向量. 这个新向量可以表示为a和b的起点重合后，以它们为邻边构成的平行四边形的一条对角线（以共同的起点为起点的那一条，见下图左）
或者表示为将 a的终点和 b的起点重合后，从a的起点指向 b的终点的这一新向量：
#+end_quote

#+ATTR_latex: :width 400   #+ATTR_HTML: :width 400  #+ATTR_ORG: :width 400
[[file:webgl/vector_add_vector.png]]

#+begin_quote
a-b：可以得到由b点前往a点的方向向量；具体是由减向量b的终点指向被减向量a终点得到的新向量。减法可以判断量物体之前的距离，同上得到新向量后，取向量模即是两点之间的距离
#+end_quote
#+ATTR_latex: :width 200   #+ATTR_HTML: :width 200  #+ATTR_ORG: :width 200
[[file:webgl/vector_sub_vector.png]]

** 向量间相乘： 分为点乘(Dot Product)v ⋅ k 和 叉乘(Cross Product)v × k
- 点乘v ⋅ k = |v||k|cosθ = cosθ  (如果v¯和k¯都是单位向量，它们的长度会等于1), 点乘的结果是一个标量，可以计算向量v和k之间的夹角θ
  - v ⋅ k = 0，两个向量正交 Orthogonal，  90度的余弦值是0
  - v ⋅ k = 1，两个向量平行 Parallel，0度的余弦值是1
  - v ⋅ k > 0, 方向基本相同，夹角在0°到90°之间
  - v ⋅ k < 0, 方向基本相反，夹角在90°到180°之间
- 叉乘v × k，在3D空间中有定义，它需要两个不平行向量作为输入，生成一个正交于两个输入向量的 *法向量* 。如果输入的两个向量也是正交的，那么叉乘之后将会产生3个互相正交的向量
#+ATTR_latex: :width 200   #+ATTR_HTML: :width 200  #+ATTR_ORG: :width 200
[[file:webgl/vectors_crossproduct.png]]

** 齐次坐标（Homogeneous coordinates）
- 在三维顶点坐标(x,y,z)引入一个新的分量w，得到向量(x,y,z,w)。向量的w分量也叫齐次坐标。
- 想要从齐次向量得到3D向量，我们可以把x、y和z坐标分别除以w坐标。我们通常不会注意这个问题，因为w分量通常是1.0。
  - 若w==1，则向量(x, y, z, 1)为空间中的点。
  - 若w==0，则向量(x, y, z, 0)为方向。 此时，这个向量就不能位移，”平移一个方向”是毫无意义的。
#+begin_quote
齐次坐标使得我们可以用同一个公式对点和方向作运算。它允许我们在3D向量上进行位移（如果没有w分量我们是不能位移向量的）
#+end_quote
** 分量的重组swizzling
- 向量的分量可以通过vec.x这种方式获取，这里x是指这个向量的第一个分量。你可以分别使用.x、.y、.z和.w来获取它们的第1、2、3、4个分量。GLSL也允许你对颜色使用rgba，或是对纹理坐标使用stpq访问相同的分量。
  - x, y, z, w:  顶点坐标的分量
  - r, g, b, a:  颜色分量
  - s, t, p, q   纹理坐标分量
- 分量重组swizzling：分量可以进行“任意搭配组合”去访问向量各个位置的数据，这也是它被称作swizzle的原因。
  #+begin_src javascript
vec4 v4 = vec4(1.0, 2.0, 3.0, 4.0);
float f;
f = v4.x; // 设f为 1.0
f = v4.w; // 设f为 4.0

vec2 v2;
v2 = v4.xy  // 设v2为（1.0， 2.0）
v2 = v4.yw  // 设v2为（2.0， 4.0）可以省略任意分量
v2 = v4.yy  // 设v2为（2.0， 2.0）可以重复任意分量
v2 = v4.wx  // 设v2为（4.0， 1.0）可以逆序
  #+end_src
- 分量重组swizzling也可以用在赋值表达式（=）的左值
  #+begin_src javascript
vec4 v4 = vec4(1.0, 2.0, 3.0, 4.0);
v4.xw = vec2(5.0, 6.0);  // v4 = (5.0, 2.0, 3.0, 6.0) x和w分量的值变了
  #+end_src


* 变换矩阵transformation matrix： 缩放、旋转、移动
#+begin_quote
- 矩阵乘法是不遵守交换律的，这意味着它们的顺序很重要。
- 当矩阵相乘时，在最右边的矩阵是第一个与向量相乘的，所以你应该从右向左读这个乘法。
- 缩旋移：在组合矩阵时，先进行缩放操作，然后是旋转，最后才是位移，否则它们会（消极地）互相影响。
#+end_quote
** 单位矩阵(Identity Matrix): 主对角线元素为1，其余元素为0, 可简记为I
#+ATTR_latex: :width 400   #+ATTR_HTML: :width 400  #+ATTR_ORG: :width 400
[[file:webgl/identity_matrix.png]]

** 旋转
- 在OpenGL的右手坐标系下，旋转规则是： 确定旋转轴后，右手握成拳头，拇指指向旋转轴的正方向，其余手指的弯曲方向即为旋转的正方向，跟手指弯曲方向一致的旋转记为正向，相反则为负向。
  - 例如： Z轴正旋转或者Z轴逆时针旋转，就是大拇指指向Z轴，其余手指弯曲的方向就是Z轴旋转正方向。这个正方向，其实是逆时针方向，所以一般规定逆时针为正就是这么来的，也就是说，旋转方向可以用旋转角度值的正负来表示。
  - 为了描述旋转（比如：绕Z轴，逆时针旋转了β角度），必须指明3个要素：
    - 旋转轴（图像将围绕旋转轴旋转）
    - 转转角度（图形旋转经过的角度）
    - 旋转方向（顺时针or逆时针）： 在调用旋转相关函数时，一般不会传入一个表示旋转方向的参数。因为我们如果旋转的角度是正值，那就是逆时针旋转，原因如上所述。

#+ATTR_latex: :width 300   #+ATTR_HTML: :width 300  #+ATTR_ORG: :width 300
[[file:webgl/z_rotation.png]]

** 平移
在顶点着色器中（而非片元着色器），逐顶点的对每个顶点坐标的分量（x，y，z）都加上一个常量（平移距离）。
如果齐次坐标的最后一个分量是1.0，那么它的前三个分量就可以表示一个点的三维坐标。
** 矩阵matrix
- 矩阵乘法不符合交换规律，也就是说 A ✖️ B 和 B ✖️ A 并不相等， 而且只有在矩阵的列数和矢量的行数相等时，才可以将两者相乘
- OpenGL API接受的矩阵要求是 *列主序* 。列主序是指以列为优先单位，在内存中逐列存储。 行主序是指以行为优先单位，在内存中逐行存储。
#+ATTR_latex: :width 800   #+ATTR_HTML: :width 800  #+ATTR_ORG: :width 800
[[file:webgl/column_order.png]]


   
* 纹理映射 texture mapping 又称纹理贴图： 纹理通常来说就是一张图片
- 纹理贴图： 就是将一张真实世界的图片（就像一张贴纸）贴到一个几何图形的表面上去，这样这个几何图形的表面看上去就是这张图片。 这张图片就是 *纹理texture* 或者叫 纹理图像。
- 纹理贴图的作用就是根据纹理图片，*为光栅化后的片元* 涂上合适的颜色。
- 纹素：组成纹理图像的像素又被称为 *纹素(texels, texture elements)*, 每一个纹素的颜色都是RGB或RGBA格式。
- Sampler取样：从纹理图像中获取纹素颜色的过程，即输入纹理坐标，返回颜色值。实际上，由于纹理像素也是有大小的，取样处的纹理坐标很可能不落在某个像素中心，所以取样通常并不是直接取纹理图像某个像素的颜色，而是通过附件的若干个像素共同计算而得。
- webgl通过 *纹理单元texture unit的机制来在同一个几何体平面上同时使用多个纹理*
#+ATTR_latex: :width 700   #+ATTR_HTML: :width 700  #+ATTR_ORG: :width 700
[[file:webgl/texel.png]]

** 例子：纹理坐标和顶点坐标映射
- 在本例中，我们绘制了一个最简单正方形，然后把同样是正方形的纹理图片贴在上面。正方形用了两个三角形来绘制，坐标和索引如下图所示，右侧显示的为纹理坐标：
#+ATTR_latex: :width 500   #+ATTR_HTML: :width 500  #+ATTR_ORG: :width 500
[[file:webgl/texture_sample_data.jpg]]

*** 例1：用整个纹理填充这个绘图区域：定义顶点数据和纹理坐标时，注意纹理坐标要与顶点一一对应
#+ATTR_latex: :width 500   #+ATTR_HTML: :width 500  #+ATTR_ORG: :width 500
[[file:webgl/texture_sample_full.png]]

*** 例2：用部分纹理填充这个绘图区域：注意纹理坐标要与顶点一一对应
- 修改一下上例中纹理坐标，只取部分纹理(左下角部分），看看有什么效果，顶点坐标不变，只是修改纹理坐标如下：
#+ATTR_latex: :width 500   #+ATTR_HTML: :width 500  #+ATTR_ORG: :width 500
[[file:webgl/texture_sample_part.png]]

*** 例3：纹理不足覆盖整个矩形，空白区域的水平&垂直填充
#+begin_src javascript
var verticesTexCoords = new Float32Array([
    // Vertex coordinate, Texture coordinate
    -0.5,  0.5,   -0.3, 1.7,
    -0.5, -0.5,   -0.3, -0.2,
    0.5,  0.5,   1.7, 1.7,
    0.5, -0.5,   1.7, -0.2
]);
#+end_src
- 由于纹理图像不足以覆盖整个矩形，所以你可以看到，在那些本该空白的区域（红色框框外），纹理又重复出现了。之所以会这样，是因为在本例子中，gl.TEXTURE_WRAP_S和gl.TEXTURE_WRAP_T使用的都是默认值gl.REPEAT
#+ATTR_latex: :width 650   #+ATTR_HTML: :width 650  #+ATTR_ORG: :width 650
[[file:webgl/texture_sample_blank.png]]

*** 例子4：通过纹理单元的机制在同一个几何体平面上同时使用多个纹理
#+begin_src javascript
// Vertex shader program
var VSHADER_SOURCE =
    'attribute vec4 a_Position;\n' +
    'attribute vec2 a_TexCoord;\n' +
    'varying vec2 v_TexCoord;\n' +
    'void main() {\n' +
    '  gl_Position = a_Position;\n' +
    '  v_TexCoord = a_TexCoord;\n' +
    '}\n';

// Fragment shader program
var FSHADER_SOURCE =
    '#ifdef GL_ES\n' +
    'precision mediump float;\n' +
    '#endif\n' +
    'uniform sampler2D u_Sampler0;\n' + // 在同一个几何体平面上同时使用多个纹理，所以这里定义了两个纹理采样器，采样器变量只能是uniform变量
    'uniform sampler2D u_Sampler1;\n' + // 有2种采样器类型：sampler2D类型对应gl.TEXTURE_2D； samplerCube类型对应gl.TEXTURE_CUBE_MAP
    'varying vec2 v_TexCoord;\n' +
    'void main() {\n' +
    '  vec4 color0 = texture2D(u_Sampler0, v_TexCoord);\n' + // 从两个纹理中取出纹素颜色
    '  vec4 color1 = texture2D(u_Sampler1, v_TexCoord);\n' + // 从纹理单元对应的采样器u_Sampler，和纹理坐标来获取纹素的颜色
    '  gl_FragColor = color0 * color1;\n' +  // 用两个纹素color0和color1来计算最终片元的颜色。有多种可能的方法，这里用颜色矢量的分量乘法
    '}\n';          // color0(r0,g0,b0,a0) * color1(r1,g1,b1,a1)  = color(r0*r1, g0*g1, b0*b1, a0*a1)

function main() {
    // Retrieve <canvas> element
    var canvas = document.getElementById('webgl');

    // Get the rendering context for WebGL
    var gl = getWebGLContext(canvas);
    if (!gl) {
        console.log('Failed to get the rendering context for WebGL');
        return;
    }

    // Initialize shaders
    if (!initShaders(gl, VSHADER_SOURCE, FSHADER_SOURCE)) {
        console.log('Failed to intialize shaders.');
        return;
    }

    // Set the vertex information
    var n = initVertexBuffers(gl);
    if (n < 0) {
        console.log('Failed to set the vertex information');
        return;
    }

    // Specify the color for clearing <canvas>
    gl.clearColor(0.0, 0.0, 0.0, 1.0);

    // Set texture
    if (!initTextures(gl, n)) {
        console.log('Failed to intialize the texture.');
        return;
    }
}

function initVertexBuffers(gl) {
    var verticesTexCoords = new Float32Array([
        // Vertex coordinate, Texture coordinate
        -0.5,  0.5,   0.0, 1.0,
        -0.5, -0.5,   0.0, 0.0,
        0.5,  0.5,   1.0, 1.0,
        0.5, -0.5,   1.0, 0.0,
    ]);
    var n = 4; // The number of vertices

    // Create a buffer object
    var vertexTexCoordBuffer = gl.createBuffer();
    if (!vertexTexCoordBuffer) {
        console.log('Failed to create the buffer object');
        return -1;
    }

    // Write the positions of vertices to a vertex shader
    gl.bindBuffer(gl.ARRAY_BUFFER, vertexTexCoordBuffer);
    gl.bufferData(gl.ARRAY_BUFFER, verticesTexCoords, gl.STATIC_DRAW);

    var FSIZE = verticesTexCoords.BYTES_PER_ELEMENT;
    //Get the storage location of a_Position, assign and enable buffer
    var a_Position = gl.getAttribLocation(gl.program, 'a_Position');
    if (a_Position < 0) {
        console.log('Failed to get the storage location of a_Position');
        return -1;
    }
    gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, FSIZE * 4, 0);
    gl.enableVertexAttribArray(a_Position);  // Enable the assignment of the buffer object

    // Get the storage location of a_TexCoord
    var a_TexCoord = gl.getAttribLocation(gl.program, 'a_TexCoord');
    if (a_TexCoord < 0) {
        console.log('Failed to get the storage location of a_TexCoord');
        return -1;
    }
    gl.vertexAttribPointer(a_TexCoord, 2, gl.FLOAT, false, FSIZE * 4, FSIZE * 2);
    gl.enableVertexAttribArray(a_TexCoord);  // Enable the buffer assignment

    return n;
}

function initTextures(gl, n) {
    var texture0 = gl.createTexture(); // 创建两个纹理对象
    var texture1 = gl.createTexture();
    if (!texture0 || !texture1) {
        console.log('Failed to create the texture object');
        return false;
    }

    // Get the storage location of u_Sampler0 and u_Sampler1
    var u_Sampler0 = gl.getUniformLocation(gl.program, 'u_Sampler0');
    var u_Sampler1 = gl.getUniformLocation(gl.program, 'u_Sampler1');
    if (!u_Sampler0 || !u_Sampler1) {
        console.log('Failed to get the storage location of u_Sampler');
        return false;
    }

    var image0 = new Image();     // 使用两个纹理，所以这里创建两个Image对象
    var image1 = new Image();
    if (!image0 || !image1) {
        console.log('Failed to create the image object');
        return false;
    }
    // Register the event handler to be called when image loading is completed
    image0.onload = function(){ loadTexture(gl, n, texture0, u_Sampler0, image0, 0); }; // 最后一个参数0，表示纹理单元0
    image1.onload = function(){ loadTexture(gl, n, texture1, u_Sampler1, image1, 1); }; // 最后一个参数1，表示纹理单元1
    image0.src = '../resources/circle.gif'; // 加载两个纹理图像
    image1.src = '../resources/sky.jpg';

    return true;
}

// 因为纹理图像的加载时异步的，我们没法预测那个先完成，所以定义这两个变量来标记两个纹理单元是否已经就绪
var g_texUnit0 = false, g_texUnit1 = false;
function loadTexture(gl, n, texture, u_Sampler, image, texUnit) {
    gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, 1);// Flip the image's y-axis
    // Make the texture unit active
    if (texUnit == 0) {           // 检测纹理单元编号texUnit
        gl.activeTexture(gl.TEXTURE0); // 激活0号纹理单元，WebGL至少支持8个纹理单元
        g_texUnit0 = true;
    } else {
        gl.activeTexture(gl.TEXTURE1);  // 激活1号纹理单元，WebGL至少支持8个纹理单元
        g_texUnit1 = true;
    }
    // Bind the texture object to the target
    gl.bindTexture(gl.TEXTURE_2D, texture);

    // Set texture parameters
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
    // Set the image to texture
    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image);

    gl.uniform1i(u_Sampler, texUnit);  // 通过纹理编号，将纹理单元0传递给片元着色器

    gl.clear(gl.COLOR_BUFFER_BIT);

    if (g_texUnit0 && g_texUnit1) {           // 确认两个纹理已经就绪后，开始绘制
        gl.drawArrays(gl.TRIANGLE_STRIP, 0, n);   // Draw the rectangle
    }
}
#+end_src

   
** 纹理贴图步骤：需要顶点着色器和片元着色器配合：
- 首先在顶点着色器中将纹理坐标映射到顶点上。通过纹理图像的纹理坐标与几何体的顶点坐标间的映射关系，来确定将那些纹理图像贴上去。app传入顶点坐标和对应的纹理坐标
- 创建纹理对象：  var texture = gl.createTexture()
- 加载纹理图像
- 反转图片的y轴，让图片坐标和纹理坐标一致。WebGL的纹理坐标系统的t轴方向和PNG、JPG等图片格式的坐标系统的Y轴方向相反，所以要先将图片Y轴反转，让图片坐标和纹理坐标一致，方便我们映射坐标。 gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, 1)
  - gl.pixelStorei(pname, param)，  第一个参数pname有以下2个取值，第二个参数指定 0（false)或者非 0（true)整数。
    - gl.UNPACK_FLIP_Y_WEBGL 对图像进行Y轴反转， 默认为0（false）
    - glUNPACK_PREMULTIPLY_ALPHA_WEBGL 将图像RGB颜色值的每一个分量乘以A， 默认值为false
      #+ATTR_latex: :width 600   #+ATTR_HTML: :width 600  #+ATTR_ORG: :width 600
      [[file:webgl/flip_y_webgl.png]]
- 激活纹理单元    gl.activeTexture(gl.TEXTURE0)  激活0号纹理单元· webgl通过 *纹理单元texture unit的机制来在同一个几何体平面上同时使用多个纹理* 。
  - 每个纹理单元有一个单元编号（gl.TEXTURE0 。。。 gl.TEXTURE8），来管理一张纹理图像，即使只是用一张纹理贴图，也要为其指定一个纹理单元，默认至少支持8个纹理单元
  - 实际上，在webgl你没法直接操作纹理对象，必须通过将纹理对象绑定到纹理单元上，然后通过操作纹理单元来操作纹理对象；
- 把纹理对象绑定到目标区域  gl.bindTexture(gl.TEXTURE_2D, texture)   webgl支持两种纹理 gl.TEXTURE_2D 二维纹理;  gl.TEXTURE_CUBE_MAP 立方体纹理
- 配置纹理对象的参数，每次调用配置一个参数，为了配置多个参数可以调用多次 gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR) 默认每个纹理参数都有默认值，通常你可以不用手动显示的调用这个函数，使用默认值就可以。
- 把纹理图像分配给纹理对象  gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGB, gl.RGB, gl.UNSIGNED_BYTE, image)  把jpg纹理图像gl.RGB颜色格式，分配给2D的纹理对象。
  - 纹理图像的颜色格式：如果是jpg就用用gl.RGB； 如果是PNG就要用gl.RGBA;  gl.UNSIGNED_BYTE 表示每个颜色分量占据1个字节
- 通过纹理编号，将纹理单元传递给片元着色器    gl.uniform1i(u_Sampler, 0);   将0号纹理传递给着色器中的取样器
- 在片元着色器，通过纹理采样器u_Sampler，和纹理坐标，从纹理图像中抽取纹理颜色，赋给当前片元  gl_FragColor = texture2D(u_Sampler, v_TexCoord)


** 配置纹理对象的参数gl.texParameteri(target, pname, param) ，将param的值赋给绑定到目标的纹理对象的pname参数上。默认每个纹理参数都有默认值，通常你可以不用手动显示的调用这个函数，使用默认值就可以。
- 第1个参数target： 指定纹理的类型，有两个值
  - gl.TEXTURE_2D二维纹理
  - gl.TEXTURE_CUBE_MAP立方体纹理
- 第2个参数pname：纹理参数的名字，决定了获取纹素颜色的方式；
  + 放大方法：gl.TEXTURE_MAG_FILTER，当绘制范围比纹理本身大时，如将16*16的纹理映射到32*32像素的空间时，纹理的尺寸不够，该参数决定了如何填充这些放大的空隙。默认值：gl.LINEAR
  + 缩小方法：gl.TEXTURE_MIN_FILTER，当的绘制范围比纹理本身小时，如将32*32的纹理映射到16*16像素的空间时，纹理的尺寸比需要的大了，需要剔除纹理图像中的部分像素。该参数决定了剔除的方法。默认：gl.NEAREST_MIPMAP_LINEAR
  + 水平填充方法：gl.TEXTURE_WRAP_S，如何对纹理图像左侧或者右侧的区域进行填充；默认值：gl.REPEAT
  + 垂直填充方法：gl.TEXTURE_WRAP_T，如何对纹理图像上方和下方的区域进行填充；默认值：gl.REPEAT
- 第3个参数param：是纹理参数的值：
  - 可以赋给 gl.TEXTURE_MAG_FILTER 和 gl.TEXTURE_MIN_FILTER 的值有2个
    1. gl.NEAREST: 使用原纹理上距离映射后像素中心最近的那个像素的颜色值，作为新像素的值。
    2. gl.LINEAR: 使用距离新像素中心最近的四个像素的颜色值的加权平均，作为新像素的值（和gl.NEAREST相比，该方法图像质量更好，但也会有较大的开销。）
  - 可以赋给 gl.TEXTURE_WRAP_S 和 gl.TEXTURE_WRAP_T 的值3个：
    1. gl.REPEAT: 平铺式的重复纹理
    2. gl.MIRRORED_REPEAT: 纹理镜像重复填充
    3. gl.CLAMP_TO_EDGE: 使用纹理边缘的像素填充




** 例子：纹理贴图
#+begin_src javascript 
// 纹理贴图需要顶点着色器和片元着色器的配合：首先在顶点着色器中提供纹理坐标和顶点，将纹理对应匹配到顶点上
var VSHADER_SOURCE =
    'attribute vec4 a_Position;\n' + // 接收从app传递过来的顶点坐标
    'attribute vec2 a_TexCoord;\n' + // 接收从app传递过来的纹理坐标
    'varying vec2 v_TexCoord;\n' +   // 通过varying 变量，把接收到的纹理坐标传递给片元着色器
    'void main() {\n' +
    '  gl_Position = a_Position;\n' +
    '  v_TexCoord = a_TexCoord;\n' +
    '}\n';

// 在片元着色器中，根据每个片元的纹理坐标从纹理图像中抽取纹理颜色，赋给当前片元
var FSHADER_SOURCE =
    '#ifdef GL_ES\n' +
    'precision mediump float;\n' +
    '#endif\n' +
    'uniform sampler2D u_Sampler;\n' + // 获取纹素颜色的取样器：即输入纹理坐标，返回颜色值。 有2中采样器类型：sampler2D类型对应gl.TEXTURE_2D； samplerCube类型对应gl.TEXTURE_CUBE_MAP。 采样器变量只能是uniform变量
    'varying vec2 v_TexCoord;\n' + // 声明同名同类型的varying变量，接收从顶点着色器传递过来的纹理坐标。
    'void main() {\n' +
    '  gl_FragColor = texture2D(u_Sampler, v_TexCoord);\n' + // 从纹理单元对应的采样器u_Sampler，和纹理坐标来获取纹素的颜色
    '}\n';

function main() {
    var canvas = document.getElementById('webgl');

    var gl = getWebGLContext(canvas);
    if (!gl) {
        console.log('Failed to get the rendering context for WebGL');
        return;
    }

    if (!initShaders(gl, VSHADER_SOURCE, FSHADER_SOURCE)) {
        console.log('Failed to intialize shaders.');
        return;
    }

    var n = initVertexBuffers(gl);
    if (n < 0) {
        console.log('Failed to set the vertex information');
        return;
    }

    gl.clearColor(0.0, 0.0, 0.0, 1.0);

    // Set texture
    if (!initTextures(gl, n)) {
        console.log('Failed to intialize the texture.');
        return;
    }
}

// 纹理贴图需要顶点着色器和片元着色器的配合：首先在顶点着色器中提供纹理坐标和顶点，将纹理对应匹配到顶点上
function initVertexBuffers(gl) {
    var verticesTexCoords = new Float32Array([
        -0.5,  0.5,   0.0, 1.0,  // 成对的记录每个顶点的顶点坐标和纹理坐标，将纹理坐标映射到顶点上。前两个是顶点坐标，后两个是纹理坐标
        -0.5, -0.5,   0.0, 0.0,
        0.5,  0.5,   1.0, 1.0,
        0.5, -0.5,   1.0, 0.0,
    ]);
    var n = 4; // 有4个顶点

    var vertexTexCoordBuffer = gl.createBuffer();
    if (!vertexTexCoordBuffer) {
        console.log('Failed to create the buffer object');
        return -1;
    }
    gl.bindBuffer(gl.ARRAY_BUFFER, vertexTexCoordBuffer);
    gl.bufferData(gl.ARRAY_BUFFER, verticesTexCoords, gl.STATIC_DRAW);   // 把顶点坐标、纹理坐标写入缓冲区对象

    var FSIZE = verticesTexCoords.BYTES_PER_ELEMENT;
    var a_Position = gl.getAttribLocation(gl.program, 'a_Position');
    if (a_Position < 0) {
        console.log('Failed to get the storage location of a_Position');
        return -1;
    }
    gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, FSIZE * 4, 0); // 把顶点坐标分配给a_Position并激活
    gl.enableVertexAttribArray(a_Position);

    var a_TexCoord = gl.getAttribLocation(gl.program, 'a_TexCoord');
    if (a_TexCoord < 0) {
        console.log('Failed to get the storage location of a_TexCoord');
        return -1;
    }
    gl.vertexAttribPointer(a_TexCoord, 2, gl.FLOAT, false, FSIZE * 4, FSIZE * 2);//把纹理坐标分配给a_TextCoord并激活。
    gl.enableVertexAttribArray(a_TexCoord);

    return n;
}

// 加载纹理图像
function initTextures(gl, n) {
    var texture = gl.createTexture();   // 创建纹理对象
    if (!texture) {
        console.log('Failed to create the texture object');
        return false;
    }

    var u_Sampler = gl.getUniformLocation(gl.program, 'u_Sampler'); // 获取u_Sampler的存储位置
    if (!u_Sampler) {
        console.log('Failed to get the storage location of u_Sampler');
        return false;
    }
    var image = new Image();  // 创建一个Image
    if (!image) {
        console.log('Failed to create the image object');
        return false;
    }
    image.onload = function(){ loadTexture(gl, n, texture, u_Sampler, image); }; // 注册当浏览器加载完图像后的回调函数
    image.src = '../resources/sky.jpg'; // 让浏览器开始加载纹理图片

    return true;
}

// 浏览器加载完图像后的回调函数，配置纹理
function loadTexture(gl, n, texture, u_Sampler, image) {
    gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, 1); // 反转纹理图像的y轴：Flip the image's y axis
    gl.activeTexture(gl.TEXTURE0); // 激活0号纹理单元，WebGL至少支持8个纹理单元
    gl.bindTexture(gl.TEXTURE_2D, texture); // 把纹理对象绑定到目标区域，webgl支持两种纹理 gl.TEXTURE_2D 二维纹理;  gl.TEXTURE_CUBE_MAP 立方体纹理

    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR); // 配置纹理参数
    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGB, gl.RGB, gl.UNSIGNED_BYTE, image); // 把jpg纹理图像image（gl.RGB颜色格式），分配给2D的纹理对象。

    gl.uniform1i(u_Sampler, 0);   // 通过纹理编号，将纹理单元0传递给片元着色器， 取样器接收的是纹理编号。

    gl.clear(gl.COLOR_BUFFER_BIT);   // Clear <canvas>

    gl.drawArrays(gl.TRIANGLE_STRIP, 0, n); // Draw the rectangle
}
#+end_src


* 投影矩阵projection matrix、视锥体frustum、裁剪坐标clipping coordinates
- 视锥体（frustum），它包含六个平面（近平面、远平面、上平面、下平面、右平面和左平面）
- 裁剪坐标（clipping coordinates）：位于这个视锥体以外的顶点都会被剪裁掉，所得的坐标结果成为裁剪坐标（clipping coordinates）
- 视锥体的形状决定了3D到2D的投影类型，如果近平面和远平面尺寸一致，那么物体上的顶点不论远近都以统一的方式投影在屏幕上，这就是正交投影orthographic projection。否则就是透视投影perspective projection。简单来说，正交投影没有近大远小的效果，而透视投影则有。

* 确定观察者状态：视点eye point、观察目标点look-at point、上方向up direction
#+begin_quote
3D和2D图形最显著的区别就是，三维物体具有深度，也就是Z轴。为了确定观察者的状态，需要3项信息
#+ATTR_latex: :width 500   #+ATTR_HTML: :width 500  #+ATTR_ORG: :width 500
[[file:webgl/camera.png]]

 1. 视点：观察者的位置，视线的起点。习惯用（eyeX, eyeY, eyeZ)表示
 2. 观察目标点：被观察物体所在的点，习惯用（atX, atY, atZ）表示。可以用来确定视线，视线从视点出发，穿过观察目标并继续延伸。
 3. 上方向：如果仅仅确定了视点和目标点，观察者还是可能以视线为轴旋转的，如下图所示。所以，为了将观察者固定住，还需要指定上方向。习惯用（upX, upY, upZ)表示。
#+ATTR_latex: :width 500   #+ATTR_HTML: :width 500  #+ATTR_ORG: :width 500
[[file:webgl/camera_up.png]]
#+end_quote
